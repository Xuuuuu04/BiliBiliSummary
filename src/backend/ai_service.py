import json
from openai import OpenAI
from src.config import Config
from typing import Dict, Optional, Callable, Generator, List
import time


class AIService:
    """AIæœåŠ¡ç±»ï¼Œç”¨äºè°ƒç”¨å¤§æ¨¡å‹ç”Ÿæˆæ€»ç»“"""
    
    def __init__(self):
        self.client = OpenAI(
            api_key=Config.OPENAI_API_KEY,
            base_url=Config.OPENAI_API_BASE,
            timeout=180.0  # ä¼˜åŒ–ï¼šå‡å°‘åˆ°3åˆ†é’Ÿè¶…æ—¶ï¼Œæé«˜å“åº”é€Ÿåº¦
        )
        self.model = Config.OPENAI_MODEL
        self.qa_model = Config.QA_MODEL
    
    def chat_stream(self, question: str, context: str, video_info: Dict, history: List[Dict] = None) -> Generator[Dict, None, None]:
        """è§†é¢‘å†…å®¹æµå¼é—®ç­”
        
        Args:
            question: ç”¨æˆ·æé—®
            context: è§†é¢‘åˆ†æç»“æœä¸Šä¸‹æ–‡
            video_info: è§†é¢‘åŸºæœ¬ä¿¡æ¯
            history: å¯¹è¯å†å²
        """
        try:
            # å®‰å…¨æ£€æŸ¥ï¼šç¡®ä¿ video_info ä¸ä¸º None
            if video_info is None:
                video_info = {}
                
            system_prompt = f"""ä½ æ˜¯ä¸€ä¸ªåŸºäºBç«™è§†é¢‘åˆ†æç»“æœçš„é—®ç­”åŠ©æ‰‹ã€‚

ã€æ ¸å¿ƒæŒ‡ä»¤ã€‘
1. **ç»å¯¹å¿ äºä¸Šä¸‹æ–‡**ï¼šä½ çš„çŸ¥è¯†åº“ä»…é™äºä¸‹æ–¹æä¾›çš„ã€è§†é¢‘åˆ†ææŠ¥å‘Šã€‘ã€‚
2. **ä¸¥ç¦ç¼–é€ **ï¼šå¦‚æœæŠ¥å‘Šä¸­æ²¡æœ‰æåˆ°ç”¨æˆ·æé—®çš„ç»†èŠ‚ï¼ˆå¦‚å…·ä½“çš„æ•°å­—ã€äººåã€ç”»é¢ç»†èŠ‚ç­‰ï¼‰ï¼Œä½ **å¿…é¡»**å›ç­”â€œæ ¹æ®å½“å‰çš„åˆ†ææŠ¥å‘Šï¼Œæˆ‘æ²¡æœ‰æ‰¾åˆ°ç›¸å…³ä¿¡æ¯â€ï¼Œä¸¥ç¦åŸºäºå¸¸è¯†æˆ–çŒœæµ‹è¿›è¡Œå›ç­”ã€‚
3. **ä¸ç¡®å®šæ€§å¤„ç†**ï¼šå¦‚æœä¿¡æ¯æ¨¡ç³Šï¼Œè¯·å¦‚å®æè¿°æŠ¥å‘Šä¸­çš„æ¨¡ç³Šä¹‹å¤„ï¼Œä¸è¦å°†å…¶ç¡®è®¤ä¸ºäº‹å®ã€‚

ã€è§†é¢‘åŸºæœ¬ä¿¡æ¯ã€‘
æ ‡é¢˜: {video_info.get('title', 'æœªçŸ¥')}
UPä¸»: {video_info.get('author', 'æœªçŸ¥')}

ã€è§†é¢‘åˆ†ææŠ¥å‘Šã€‘
{context}
"""
            messages = [{"role": "system", "content": system_prompt}]
            
            # æ·»åŠ å†å²è®°å½•
            if history:
                messages.extend(history)
            
            # æ·»åŠ å½“å‰é—®é¢˜
            messages.append({"role": "user", "content": question})

            stream = self.client.chat.completions.create(
                model=self.qa_model,
                messages=messages,
                temperature=0.4, # QAå¯ä»¥ç¨å¾®é«˜ä¸€ç‚¹ç‚¹ä¿æŒå¯¹è¯è¿è´¯ï¼Œä½†ä»éœ€æ§åˆ¶åœ¨ä½ä½
                stream=True
            )

            for chunk in stream:
                if chunk.choices and len(chunk.choices) > 0:
                    delta = chunk.choices[0].delta
                    if hasattr(delta, 'content') and delta.content:
                        yield {'type': 'content', 'content': delta.content}
            
            yield {'type': 'done'}

        except Exception as e:
            print(f"[é”™è¯¯] QAé—®ç­”å¤±è´¥: {str(e)}")
            yield {'type': 'error', 'error': str(e)}

    def generate_summary(self, video_info: Dict, content: str) -> Dict:
        """ç”Ÿæˆè§†é¢‘æ€»ç»“"""
        try:
            # æ„å»ºæç¤ºè¯
            prompt = self._build_summary_prompt(video_info, content)
            
            # è°ƒç”¨å¤§æ¨¡å‹
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system",
                        "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è§†é¢‘å†…å®¹åˆ†æåŠ©æ‰‹ï¼Œæ“…é•¿æ€»ç»“è§†é¢‘å†…å®¹å¹¶æå–å…³é”®ä¿¡æ¯ã€‚"
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                temperature=0.7,
                max_tokens=4000
            )
            
            # å¤„ç†ä¸åŒAPIå“åº”æ ¼å¼
            summary_text = self._extract_content(response)
            tokens_used = self._extract_tokens(response)
            
            return {
                'success': True,
                'data': {
                    'summary': summary_text,
                    'tokens_used': tokens_used
                }
            }
        except Exception as e:
            print(f"[é”™è¯¯] ç”Ÿæˆæ€»ç»“å¤±è´¥: {str(e)}")
            print(f"[è°ƒè¯•] é”™è¯¯ç±»å‹: {type(e).__name__}")
            import traceback
            traceback.print_exc()
            return {
                'success': False,
                'error': f'ç”Ÿæˆæ€»ç»“å¤±è´¥: {str(e)}'
            }
    
    def generate_mindmap(self, video_info: Dict, content: str, summary: Optional[str] = None) -> Dict:
        """ç”Ÿæˆæ€ç»´å¯¼å›¾ï¼ˆMarkdownæ ¼å¼ï¼‰"""
        try:
            prompt = self._build_mindmap_prompt(video_info, content, summary)
            
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system",
                        "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ€ç»´å¯¼å›¾è®¾è®¡å¸ˆï¼Œæ“…é•¿å°†å¤æ‚å†…å®¹ç»“æ„åŒ–ä¸ºæ¸…æ™°çš„æ€ç»´å¯¼å›¾ã€‚"
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                temperature=0.7,
                max_tokens=2000
            )
            
            # å¤„ç†ä¸åŒAPIå“åº”æ ¼å¼
            mindmap_text = self._extract_content(response)
            tokens_used = self._extract_tokens(response)
            
            return {
                'success': True,
                'data': {
                    'mindmap': mindmap_text,
                    'tokens_used': tokens_used
                }
            }
        except Exception as e:
            print(f"[é”™è¯¯] ç”Ÿæˆæ€ç»´å¯¼å›¾å¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
            return {
                'success': False,
                'error': f'ç”Ÿæˆæ€ç»´å¯¼å›¾å¤±è´¥: {str(e)}'
            }
    
    def generate_full_analysis(self, video_info: Dict, content: str, video_frames: Optional[list] = None, retry_count: int = 0) -> Dict:
        """ç”Ÿæˆå®Œæ•´åˆ†æï¼ˆåŒ…æ‹¬æ€»ç»“å’Œæ€ç»´å¯¼å›¾ï¼‰

        Args:
            video_info: è§†é¢‘ä¿¡æ¯
            content: æ–‡æœ¬å†…å®¹ï¼ˆå­—å¹•/å¼¹å¹•ï¼‰
            video_frames: å¯é€‰çš„è§†é¢‘å¸§ï¼ˆbase64ç¼–ç åˆ—è¡¨ï¼‰
        """
        try:
            print(f"[è°ƒè¯•] å¼€å§‹ç”Ÿæˆåˆ†æ - æ¨¡å‹: {self.model}")
            print(f"[è°ƒè¯•] API Base: {Config.OPENAI_API_BASE}")
            print(f"[è°ƒè¯•] è§†é¢‘å¸§æ•°é‡: {len(video_frames) if video_frames else 0}")

            # æ„å»ºç»¼åˆæç¤ºè¯ï¼ˆæ”¯æŒå¼¹å¹•å†…å®¹ï¼‰
            danmaku_preview = None
            if content and 'ã€å¼¹å¹•å†…å®¹ï¼ˆéƒ¨åˆ†ï¼‰ã€‘' in content:
                # æå–å¼¹å¹•é¢„è§ˆç”¨äºåˆ†æ
                danmaku_preview = content
            prompt = self._build_full_analysis_prompt(video_info, content, has_video_frames=bool(video_frames), danmaku_content=danmaku_preview)
            print(f"[è°ƒè¯•] æç¤ºè¯é•¿åº¦: {len(prompt)}")

            # æ„å»ºæ¶ˆæ¯å†…å®¹ - é€‚é…æ–°çš„å¤šæ¨¡æ€æ ¼å¼
            user_content = [
                {
                    "type": "text",
                    "text": prompt
                }
            ]

            # æ·»åŠ è§†é¢‘å¸§ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
            if video_frames and len(video_frames) > 0:
                for idx, frame_base64 in enumerate(video_frames):
                    user_content.append({
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/jpeg;base64,{frame_base64}",
                            "detail": "low"  # ä½¿ç”¨low detailä»¥èŠ‚çœtoken
                        }
                    })
                    print(f"[è°ƒè¯•] æ·»åŠ ç¬¬ {idx+1} å¸§åˆ°æ¶ˆæ¯ä¸­")

            # ä½¿ç”¨æ–°çš„æ¶ˆæ¯æ ¼å¼è°ƒç”¨API
            messages = [
                {
                    "role": "system",
                    "content": """ä½ æ˜¯ä¸€ä½èµ„æ·±çš„Bç«™è§†é¢‘å†…å®¹åˆ†æä¸“å®¶ï¼Œæ“…é•¿ï¼š
1. æ·±åº¦å†…å®¹è§£æ - æå–æ‰€æœ‰çŸ¥è¯†ç‚¹ã€åˆ†æç›®çš„å’Œå«ä¹‰
2. ç»“æ„åŒ–å‘ˆç° - æ¸…æ™°çš„æ€ç»´å¯¼å›¾å’Œå±‚æ¬¡ç»“æ„
3. äº’åŠ¨æ•°æ®åˆ†æ - å¼¹å¹•æƒ…æ„Ÿã€çƒ­ç‚¹ã€è¯äº‘åˆ†æ
4. ç»¼åˆè¯„ä»· - å¤šç»´åº¦è¯„åˆ†å’Œå­¦ä¹ å»ºè®®

ä½ èƒ½åŒæ—¶åˆ†æè§†é¢‘ç”»é¢ã€æ–‡å­—å†…å®¹å’Œå¼¹å¹•äº’åŠ¨ï¼Œæä¾›å…¨é¢ã€ä¸“ä¸šã€æ˜“è¯»çš„å››å¤§æ¿å—åˆ†ææŠ¥å‘Šã€‚
è¯·ä¸¥æ ¼æŒ‰ç…§è¦æ±‚çš„å››å¤§æ¿å—ç»“æ„è¾“å‡ºï¼Œå†…å®¹è¯¦å®ã€æ ¼å¼è§„èŒƒã€é€»è¾‘æ¸…æ™°ã€‚"""
                },
                {
                    "role": "user",
                    "content": user_content
                }
            ]

            print(f"[è°ƒè¯•] å‘é€è¯·æ±‚åˆ°API...")
            response = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                temperature=0.2,  # æè‡´ä¼˜åŒ–ï¼šæä½æ¸©åº¦å‡å°‘å¹»è§‰
                max_tokens=8000,
                timeout=240
            )
            
            print(f"[è°ƒè¯•] APIå“åº”ç±»å‹: {type(response)}")
            print(f"[è°ƒè¯•] APIå“åº”å‰100å­—ç¬¦: {str(response)[:100]}")
            
            # å¤„ç†ä¸åŒAPIå“åº”æ ¼å¼
            analysis_text = self._extract_content(response)
            tokens_used = self._extract_tokens(response)
            
            # å°è¯•è§£æç»“æ„åŒ–å†…å®¹
            parsed_content = self._parse_analysis_response(analysis_text)
            
            return {
                'success': True,
                'data': {
                    'full_analysis': analysis_text,
                    'parsed': parsed_content,
                    'tokens_used': tokens_used
                }
            }
        except Exception as e:
            print(f"[é”™è¯¯] ç”Ÿæˆå®Œæ•´åˆ†æå¤±è´¥: {str(e)}")
            print(f"[è°ƒè¯•] é”™è¯¯ç±»å‹: {type(e).__name__}")

            # é’ˆå¯¹ç½‘ç»œå’Œè¶…æ—¶é”™è¯¯çš„ç‰¹æ®Šå¤„ç†
            if any(keyword in str(e).lower() for keyword in ['timeout', 'connection', 'network', '504', '502', '500']):
                if retry_count < 2:  # æœ€å¤šé‡è¯•2æ¬¡
                    print(f"[é‡è¯•] æ£€æµ‹åˆ°ç½‘ç»œé”™è¯¯ï¼Œæ­£åœ¨è¿›è¡Œç¬¬{retry_count + 1}æ¬¡é‡è¯•...")
                    print(f"[é‡è¯•] é”™è¯¯è¯¦æƒ…: {str(e)}")

                    if video_frames and len(video_frames) > 4:  # å¦‚æœå¸§æ•°å¤ªå¤šï¼Œå‡å°‘åˆ°4å¸§
                        reduced_frames = video_frames[:4]
                        print(f"[é™çº§] å‡å°‘è§†é¢‘å¸§æ•°é‡: {len(video_frames)} â†’ {len(reduced_frames)}")
                        return self.generate_full_analysis(video_info, content, reduced_frames, retry_count + 1)
                    elif video_frames and retry_count == 0:  # ç¬¬ä¸€æ¬¡é‡è¯•ï¼Œå»é™¤è§†é¢‘å¸§
                        print(f"[é™çº§] æ”¾å¼ƒè§†é¢‘å¸§ï¼Œä»…ä½¿ç”¨æ–‡æœ¬åˆ†æ")
                        return self.generate_full_analysis(video_info, content, None, retry_count + 1)

            import traceback
            traceback.print_exc()
            return {
                'success': False,
                'error': f'ç”Ÿæˆåˆ†æå¤±è´¥: {str(e)}'
            }

    def generate_full_analysis_stream(self, video_info: Dict, content: str, video_frames: Optional[list] = None,
                                    progress_callback: Optional[Callable] = None) -> Generator[Dict, None, None]:
        """æµå¼ç”Ÿæˆå®Œæ•´åˆ†æï¼Œæ”¯æŒå®æ—¶è¿›åº¦å›è°ƒ

        Args:
            video_info: è§†é¢‘ä¿¡æ¯
            content: æ–‡æœ¬å†…å®¹ï¼ˆå­—å¹•/å¼¹å¹•ï¼‰
            video_frames: å¯é€‰çš„è§†é¢‘å¸§ï¼ˆbase64ç¼–ç åˆ—è¡¨ï¼‰
            progress_callback: è¿›åº¦å›è°ƒå‡½æ•°ï¼Œæ¥æ”¶ (stage, progress, message, tokens_used)

        Yields:
            Dict: åŒ…å«çŠ¶æ€ã€è¿›åº¦ã€å†…å®¹å—ç­‰ä¿¡æ¯çš„å­—å…¸
        """
        try:
            # å‘é€å¼€å§‹ä¿¡å·
            yield {
                'type': 'start',
                'stage': 'preparing',
                'progress': 0,
                'message': 'å‡†å¤‡ç”Ÿæˆåˆ†æ...',
                'tokens_used': 0,
                'timestamp': time.time()
            }

            if progress_callback:
                progress_callback('preparing', 0, 'å‡†å¤‡ç”Ÿæˆåˆ†æ...', 0)

            print(f"[è°ƒè¯•] å¼€å§‹æµå¼ç”Ÿæˆåˆ†æ - æ¨¡å‹: {self.model}")
            print(f"[è°ƒè¯•] API Base: {Config.OPENAI_API_BASE}")
            print(f"[è°ƒè¯•] è§†é¢‘å¸§æ•°é‡: {len(video_frames) if video_frames else 0}")

            # æ„å»ºç»¼åˆæç¤ºè¯
            danmaku_preview = None
            if content and 'ã€å¼¹å¹•å†…å®¹ï¼ˆéƒ¨åˆ†ï¼‰ã€‘' in content:
                danmaku_preview = content
            prompt = self._build_full_analysis_prompt(video_info, content, has_video_frames=bool(video_frames), danmaku_content=danmaku_preview)

            yield {
                'type': 'progress',
                'stage': 'building_prompt',
                'progress': 10,
                'message': 'æ„å»ºåˆ†ææç¤ºè¯...',
                'tokens_used': 0,
                'timestamp': time.time()
            }

            if progress_callback:
                progress_callback('building_prompt', 10, 'æ„å»ºåˆ†ææç¤ºè¯...', 0)

            # æ„å»ºæ¶ˆæ¯å†…å®¹
            user_content = [
                {
                    "type": "text",
                    "text": prompt
                }
            ]

            # æ·»åŠ è§†é¢‘å¸§
            if video_frames and len(video_frames) > 0:
                for idx, frame_base64 in enumerate(video_frames):
                    user_content.append({
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/jpeg;base64,{frame_base64}",
                            "detail": "low"
                        }
                    })
                    print(f"[è°ƒè¯•] æ·»åŠ ç¬¬ {idx+1} å¸§åˆ°æ¶ˆæ¯ä¸­")

            messages = [
                {
                    "role": "system",
                    "content": """ä½ æ˜¯ä¸€ä½èµ„æ·±çš„Bç«™è§†é¢‘å†…å®¹åˆ†æä¸“å®¶ï¼Œæ“…é•¿ï¼š
1. æ·±åº¦å†…å®¹è§£æ - æå–æ‰€æœ‰çŸ¥è¯†ç‚¹ã€åˆ†æç›®çš„å’Œå«ä¹‰
2. ç»“æ„åŒ–å‘ˆç° - æ¸…æ™°çš„æ€ç»´å¯¼å›¾å’Œå±‚æ¬¡ç»“æ„
3. äº’åŠ¨æ•°æ®åˆ†æ - å¼¹å¹•æƒ…æ„Ÿã€çƒ­ç‚¹ã€è¯äº‘åˆ†æ
4. ç»¼åˆè¯„ä»· - å¤šç»´åº¦è¯„åˆ†å’Œå­¦ä¹ å»ºè®®

ä½ èƒ½åŒæ—¶åˆ†æè§†é¢‘ç”»é¢ã€æ–‡å­—å†…å®¹å’Œå¼¹å¹•äº’åŠ¨ï¼Œæä¾›å…¨é¢ã€ä¸“ä¸šã€æ˜“è¯»çš„å››å¤§æ¿å—åˆ†ææŠ¥å‘Šã€‚
è¯·ä¸¥æ ¼æŒ‰ç…§è¦æ±‚çš„å››å¤§æ¿å—ç»“æ„è¾“å‡ºï¼Œå†…å®¹è¯¦å®ã€æ ¼å¼è§„èŒƒã€é€»è¾‘æ¸…æ™°ã€‚"""
                },
                {
                    "role": "user",
                    "content": user_content
                }
            ]

            yield {
                'type': 'progress',
                'stage': 'calling_api',
                'progress': 20,
                'message': 'è°ƒç”¨AIæ¨¡å‹ç”Ÿæˆåˆ†æ...',
                'tokens_used': 0,
                'timestamp': time.time()
            }

            if progress_callback:
                progress_callback('calling_api', 20, 'è°ƒç”¨AIæ¨¡å‹ç”Ÿæˆåˆ†æ...', 0)

            print(f"[è°ƒè¯•] å‘é€æµå¼è¯·æ±‚åˆ°API...")

            # æµå¼è°ƒç”¨API
            stream = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                temperature=0.3,  # æè‡´ä¼˜åŒ–ï¼šä½æ¸©åº¦é™ä½æµå¼è¾“å‡ºå¹»è§‰
                max_tokens=8000,
                timeout=240,
                stream=True  # å¯ç”¨æµå¼ä¼ è¾“
            )

            full_content = ""
            chunk_count = 0
            last_progress_update = time.time()

            yield {
                'type': 'progress',
                'stage': 'streaming',
                'progress': 30,
                'message': 'æ­£åœ¨æ¥æ”¶AIåˆ†æç»“æœ...',
                'tokens_used': 0,
                'timestamp': time.time()
            }

            if progress_callback:
                progress_callback('streaming', 30, 'æ­£åœ¨æ¥æ”¶AIåˆ†æç»“æœ...', 0)

            # å¤„ç†æµå¼å“åº”
            for chunk in stream:
                chunk_count += 1

                # æå–å†…å®¹å—
                if chunk.choices and len(chunk.choices) > 0:
                    delta = chunk.choices[0].delta
                    if hasattr(delta, 'content') and delta.content:
                        content_piece = delta.content
                        full_content += content_piece

                        # æ¯éš”ä¸€å®šæ—¶é—´æˆ–ä¸€å®šæ•°é‡çš„chunkå‘é€è¿›åº¦æ›´æ–°
                        current_time = time.time()
                        if current_time - last_progress_update > 0.5 or chunk_count % 10 == 0:
                            progress = min(30 + (chunk_count * 2), 90)  # 30%-90%

                            yield {
                                'type': 'progress',
                                'stage': 'streaming',
                                'progress': progress,
                                'message': f'æ­£åœ¨æ·±åº¦è§£æå†…å®¹...',
                                'tokens_used': chunk_count * 10,  # ä¼°ç®—tokenæ•°
                                'content_length': len(full_content),
                                'timestamp': current_time
                            }

                            if progress_callback:
                                progress_callback('streaming', progress, f'æ­£åœ¨æ·±åº¦è§£æå†…å®¹...', chunk_count * 10)

                            last_progress_update = current_time

                # å‘é€å†…å®¹å—ï¼ˆå¯é€‰ï¼Œç”¨äºå®æ—¶æ˜¾ç¤ºéƒ¨åˆ†å†…å®¹ï¼‰
                if chunk_count % 20 == 0:  # æ¯20ä¸ªchunkå‘é€ä¸€æ¬¡å†…å®¹é¢„è§ˆ
                    yield {
                        'type': 'content_preview',
                        'stage': 'streaming',
                        'progress': min(30 + (chunk_count * 2), 90),
                        'message': 'æ›´æ–°å†…å®¹é¢„è§ˆ...',
                        'content_preview': full_content[-500:] if len(full_content) > 500 else full_content,
                        'content_length': len(full_content),
                        'timestamp': time.time()
                    }

            # æœ€ç»ˆå¤„ç†
            yield {
                'type': 'progress',
                'stage': 'processing',
                'progress': 95,
                'message': 'å¤„ç†æœ€ç»ˆç»“æœ...',
                'tokens_used': chunk_count * 10,
                'timestamp': time.time()
            }

            if progress_callback:
                progress_callback('processing', 95, 'å¤„ç†æœ€ç»ˆç»“æœ...', chunk_count * 10)

            # è§£ææœ€ç»ˆç»“æœ
            parsed_content = self._parse_analysis_response(full_content)
            total_tokens = chunk_count * 15  # æ›´å‡†ç¡®çš„tokenä¼°ç®—

            yield {
                'type': 'complete',
                'stage': 'completed',
                'progress': 100,
                'message': 'åˆ†æå®Œæˆï¼',
                'tokens_used': total_tokens,
                'content_length': len(full_content),
                'full_analysis': full_content,
                'parsed': parsed_content,
                'chunk_count': chunk_count,
                'timestamp': time.time()
            }

            if progress_callback:
                progress_callback('completed', 100, 'åˆ†æå®Œæˆï¼', total_tokens)

            print(f"[è°ƒè¯•] æµå¼åˆ†æå®Œæˆ - æ€»å…± {chunk_count} ä¸ªchunk, çº¦ {total_tokens} tokens")

        except Exception as e:
            print(f"[é”™è¯¯] æµå¼ç”Ÿæˆåˆ†æå¤±è´¥: {str(e)}")
            print(f"[è°ƒè¯•] é”™è¯¯ç±»å‹: {type(e).__name__}")

            # é”™è¯¯å¤„ç†å’Œé™çº§ç­–ç•¥
            if any(keyword in str(e).lower() for keyword in ['timeout', 'connection', 'network', '504', '502', '500']):
                yield {
                    'type': 'error',
                    'stage': 'retrying',
                    'progress': 0,
                    'message': f'ç½‘ç»œé”™è¯¯ï¼Œå°è¯•é™çº§å¤„ç†... é”™è¯¯: {str(e)}',
                    'error_type': 'network',
                    'timestamp': time.time()
                }

                # é™çº§åˆ°æ–‡æœ¬åˆ†æ
                if video_frames:
                    yield {
                        'type': 'progress',
                        'stage': 'fallback',
                        'progress': 10,
                        'message': 'é™çº§åˆ°çº¯æ–‡æœ¬åˆ†æ...',
                        'timestamp': time.time()
                    }

                    # é€’å½’è°ƒç”¨ï¼Œä¸ä½¿ç”¨è§†é¢‘å¸§
                    yield from self.generate_full_analysis_stream(video_info, content, None, progress_callback)
                    return

            import traceback
            traceback.print_exc()

            yield {
                'type': 'error',
                'stage': 'failed',
                'progress': 0,
                'message': f'åˆ†æå¤±è´¥: {str(e)}',
                'error_type': type(e).__name__,
                'timestamp': time.time()
            }

    def generate_article_analysis_stream(self, article_info: Dict, content: str) -> Generator[Dict, None, None]:
        """ä¸“æ æ–‡ç« æ·±åº¦åˆ†æ"""
        try:
            prompt = f"""ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„æ·±åº¦æŠ¥é“è¯„è®ºå‘˜ã€‚è¯·ä¸ºä»¥ä¸‹Bç«™ä¸“æ æ–‡ç« ç”Ÿæˆä¸€ä»½è¯¦å°½çš„åˆ†ææŠ¥å‘Šã€‚

ã€æ–‡ç« ä¿¡æ¯ã€‘
æ ‡é¢˜ï¼š{article_info.get('title', 'æœªçŸ¥')}
ä½œè€…ï¼š{article_info.get('author', 'æœªçŸ¥')}

ã€æ–‡ç« å®Œæ•´å†…å®¹ã€‘
{content[:Config.MAX_SUBTITLE_LENGTH]}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ç»“æ„æä¾›åˆ†ææŠ¥å‘Šï¼š
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

## ğŸ“‹ æ–‡ç« æ·±åº¦è§£æ
- **æ ¸å¿ƒè®ºç‚¹**ï¼šç”¨ä¸€å¥è¯æ¦‚æ‹¬æ–‡ç« æƒ³è¦è¡¨è¾¾çš„æœ€æ ¸å¿ƒè§‚ç‚¹ã€‚
- **å†…å®¹ç²¾è¦**ï¼šç³»ç»Ÿæ€§åœ°æ€»ç»“æ–‡ç« çš„åˆ†ç‚¹è®ºè¿°ï¼Œé€»è¾‘æ¸…æ™°ï¼Œå†…å®¹å……å®ã€‚
- **æ·±åº¦ç‚¹è¯„**ï¼šåˆ†ææ–‡ç« çš„å†™ä½œé£æ ¼ã€ä¸“ä¸šæ·±åº¦ä»¥åŠå¯¹è¡Œä¸š/è¯»è€…çš„å¯å‘æ„ä¹‰ã€‚

## ğŸ’¡ çŸ¥è¯†å›¾è°±
- æå–å¹¶è§£é‡Šæ–‡ç« ä¸­æåˆ°çš„ä¸“ä¸šæœ¯è¯­æˆ–èƒŒæ™¯çŸ¥è¯†ã€‚

## ğŸš€ é˜…è¯»å»ºè®®
- é€‚åˆå“ªç±»äººç¾¤æ·±åº¦é˜…è¯»ï¼Ÿ
- ç›¸å…³çš„å»¶ä¼¸é˜…è¯»æ–¹å‘ã€‚
"""
            messages = [
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä½èµ„æ·±çš„Bç«™ä¸“æ åˆ†æä¸“å®¶ï¼Œæ“…é•¿é€»è¾‘åˆ†æä¸æ·±åº¦æ€»ç»“ã€‚"},
                {"role": "user", "content": prompt}
            ]

            stream = self.client.chat.completions.create(
                model=self.qa_model, # ä½¿ç”¨é€»è¾‘æ›´å¼ºçš„QAæ¨¡å‹è¿›è¡Œæ–‡ç« åˆ†æ
                messages=messages,
                temperature=0.3,
                stream=True
            )

            full_content = ""
            for chunk in stream:
                if chunk.choices and len(chunk.choices) > 0:
                    delta = chunk.choices[0].delta
                    if hasattr(delta, 'content') and delta.content:
                        full_content += delta.content
                        yield {'type': 'content', 'content': delta.content}
            
            # è§£ææ–‡ç« å†…å®¹
            sections = {'summary': full_content, 'danmaku': 'ä¸“æ æ–‡ç« æš‚æ— å¼¹å¹•åˆ†æ', 'comments': 'ä¸“æ æ–‡ç« æš‚æ— è¯„è®ºåˆ†æ'}
            yield {'type': 'final', 'parsed': sections, 'full_analysis': full_content}

        except Exception as e:
            yield {'type': 'error', 'error': str(e)}

    def generate_user_analysis(self, user_info: Dict, recent_videos: List[Dict]) -> str:
        """ç”ŸæˆUPä¸»æ·±åº¦ç”»åƒï¼ˆåŒæ­¥è¿”å›å­—ç¬¦ä¸²ï¼‰"""
        try:
            videos_text = "\n".join([f"- {v['title']} (æ’­æ”¾: {v['play']}, æ—¶é•¿: {v['length']})" for v in recent_videos])
            prompt = f"""ä½ æ˜¯ä¸€ä½èµ„æ·±çš„è‡ªåª’ä½“è¡Œä¸šåˆ†æå¸ˆã€‚è¯·æ ¹æ®ä»¥ä¸‹UPä¸»çš„å…¬å¼€ä¿¡æ¯å’Œè¿‘æœŸä½œå“æ•°æ®ï¼Œç”Ÿæˆä¸€ä»½**æ·±åº¦ã€ä¸“ä¸šä¸”å…·æœ‰æ´å¯ŸåŠ›**çš„UPä¸»ç”»åƒæŠ¥å‘Šã€‚

ã€UPä¸»åŸºç¡€ä¿¡æ¯ã€‘
- æ˜µç§°ï¼š{user_info.get('name')}
- ç­¾åï¼š{user_info.get('sign')}
- ç­‰çº§ï¼šL{user_info.get('level')}
- è®¤è¯ä¿¡æ¯ï¼š{user_info.get('official') or 'æ™®é€šç”¨æˆ·'}

ã€è¿‘æœŸä½œå“æ•°æ®ï¼ˆé‡‡æ ·ï¼‰ã€‘
{videos_text}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
è¯·æŒ‰ä»¥ä¸‹ç»“æ„è¾“å‡ºæ·±åº¦åˆ†æï¼ˆä½¿ç”¨ Markdown æ ¼å¼ï¼Œå¤šç”¨ Emojiï¼‰ï¼š
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

### ğŸ­ åˆ›ä½œè€…æ ‡ç­¾
- ç”¨ 3-5 ä¸ªå…³é”®è¯ç²¾å‡†å®šä¹‰è¯¥ UP ä¸»ï¼ˆå¦‚ï¼šç¡¬æ ¸æŠ€æœ¯æµã€æç®€ä¸»ä¹‰è€…ã€é«˜äº§èµ›æ¯çŒªç­‰ï¼‰ã€‚

### ğŸ“ˆ å†…å®¹é£æ ¼ä¸è°ƒæ€§
- åˆ†æå…¶è§†é¢‘çš„æ ‡é¢˜é£æ ¼ã€é€‰é¢˜åå¥½åŠå†…å®¹æ·±åº¦ã€‚
- è§‚å¯Ÿå…¶ä½œå“çš„ç”Ÿå‘½åŠ›ï¼ˆä»æ’­æ”¾é‡ä¸é€‰é¢˜çš„å…³è”åº¦åˆ†æï¼‰ã€‚

### ğŸ’ æ ¸å¿ƒä»·å€¼ä¸»å¼ 
- è¯¥ UP ä¸»ä¸ºç²‰ä¸æä¾›äº†ä»€ä¹ˆç‹¬ç‰¹ä»·å€¼ï¼Ÿï¼ˆæ˜¯çŸ¥è¯†è·å–ã€æƒ…ç»ªä»·å€¼è¿˜æ˜¯å®¡ç¾å…±é¸£ï¼Ÿï¼‰

### ğŸš€ å‘å±•æ½œåŠ›è¯„ä¼°
- åŸºäºè¿‘æœŸä½œå“çš„è¡¨ç°ï¼Œåˆ†æå…¶å†…å®¹çš„å‚ç›´åº¦åŠæœªæ¥å¢é•¿ç©ºé—´ã€‚

### ğŸ’¡ åˆä½œ/å…³æ³¨å»ºè®®
- ç»™æƒ³å…³æ³¨è¯¥ UP ä¸»æˆ–ä¸å…¶åˆä½œçš„å“ç‰Œæ–¹æä¾›ä¸€æ¡è¯šæ³çš„å»ºè®®ã€‚

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
è¯·ä¿æŒä¸“ä¸šã€å®¢è§‚ä¸”å¯Œæœ‰æ–‡å­¦è‰²å½©çš„ç¬”è§¦ï¼Œå­—æ•°åœ¨ 300-500 å­—å·¦å³ã€‚"""
            
            response = self.client.chat.completions.create(
                model=self.qa_model,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.6,
                max_tokens=1000
            )
            return self._extract_content(response)
        except Exception as e:
            return f"æš‚æ—¶æ— æ³•ç”ŸæˆUPä¸»ç”»åƒ: {str(e)}"
    
    def _build_summary_prompt(self, video_info: Dict, content: str) -> str:
        """æ„å»ºæ€»ç»“æç¤ºè¯"""
        return f"""è¯·ä¸ºä»¥ä¸‹Bç«™è§†é¢‘ç”Ÿæˆè¯¦ç»†çš„æ€»ç»“æŠ¥å‘Šï¼š

ã€è§†é¢‘ä¿¡æ¯ã€‘
æ ‡é¢˜ï¼š{video_info.get('title', 'æœªçŸ¥')}
ä½œè€…ï¼š{video_info.get('author', 'æœªçŸ¥')}
ç®€ä»‹ï¼š{video_info.get('desc', 'æ— ')}

ã€è§†é¢‘å†…å®¹ã€‘
{content[:Config.MAX_SUBTITLE_LENGTH]}

è¯·æä¾›ä»¥ä¸‹å†…å®¹ï¼š
1. **å†…å®¹æ¦‚è¿°**ï¼ˆ3-5å¥è¯æ¦‚æ‹¬è§†é¢‘ä¸»è¦å†…å®¹ï¼‰
2. **è¯¦ç»†æ€»ç»“**ï¼ˆæŒ‰é€»è¾‘ç»“æ„è¯¦ç»†æ€»ç»“è§†é¢‘å†…å®¹ï¼Œåˆ†æ®µå‘ˆç°ï¼‰
3. **å…³é”®è¦ç‚¹**ï¼ˆåˆ—å‡º5-10ä¸ªæ ¸å¿ƒçŸ¥è¯†ç‚¹ï¼‰
4. **é€‚ç”¨äººç¾¤**ï¼ˆè¯´æ˜è¿™ä¸ªè§†é¢‘é€‚åˆä»€ä¹ˆäººè§‚çœ‹ï¼‰
5. **å­¦ä¹ å»ºè®®**ï¼ˆç»™å‡ºå…·ä½“çš„å­¦ä¹ å»ºè®®ï¼‰

è¯·ç”¨æ¸…æ™°çš„Markdownæ ¼å¼è¾“å‡ºï¼Œä½¿ç”¨æ ‡é¢˜ã€åˆ—è¡¨ç­‰æ ¼å¼åŒ–å…ƒç´ ã€‚"""
    
    def _build_mindmap_prompt(self, video_info: Dict, content: str, summary: Optional[str]) -> str:
        """æ„å»ºæ€ç»´å¯¼å›¾æç¤ºè¯"""
        base_content = f"""è¯·ä¸ºä»¥ä¸‹è§†é¢‘å†…å®¹ç”Ÿæˆæ€ç»´å¯¼å›¾ï¼ˆä½¿ç”¨Markdownæ ¼å¼ï¼‰ï¼š

ã€è§†é¢‘æ ‡é¢˜ã€‘
{video_info.get('title', 'æœªçŸ¥')}

ã€è§†é¢‘å†…å®¹ã€‘
{content[:Config.MAX_SUBTITLE_LENGTH]}
"""
        
        if summary:
            base_content += f"\nã€å·²æœ‰æ€»ç»“ã€‘\n{summary}\n"
        
        base_content += """
è¯·ç”¨Markdownæ ¼å¼çš„å±‚çº§åˆ—è¡¨ç”Ÿæˆæ€ç»´å¯¼å›¾ï¼Œç»“æ„æ¸…æ™°ï¼Œå±‚æ¬¡åˆ†æ˜ã€‚

æ ¼å¼ç¤ºä¾‹ï¼š
# è§†é¢‘æ ‡é¢˜
## ç¬¬ä¸€éƒ¨åˆ†ï¼šæ ¸å¿ƒæ¦‚å¿µ
- è¦ç‚¹1
  - å­è¦ç‚¹1.1
  - å­è¦ç‚¹1.2
- è¦ç‚¹2
## ç¬¬äºŒéƒ¨åˆ†ï¼šå…·ä½“å†…å®¹
- è¦ç‚¹3
  - å­è¦ç‚¹3.1

è¯·ç¡®ä¿ï¼š
1. æœ€å¤š4å±‚å±‚çº§
2. æ¯ä¸ªèŠ‚ç‚¹ç®€æ´æ˜äº†
3. é€»è¾‘ç»“æ„æ¸…æ™°
4. æ¶µç›–ä¸»è¦å†…å®¹"""
        
        return base_content
    
    def _build_full_analysis_prompt(self, video_info: Dict, content: str, has_video_frames: bool = False, danmaku_content: str = None) -> str:
        """æ„å»ºå®Œæ•´åˆ†ææç¤ºè¯ï¼ˆæè‡´é˜²å¹»è§‰ä¼˜åŒ–ç‰ˆï¼‰"""
        video_analysis_hint = ""
        if has_video_frames:
            video_analysis_hint = """

**è§†è§‰åˆ†ææŒ‡ä»¤ (é‡è¦)**ï¼š
- æˆ‘æä¾›äº†è§†é¢‘çš„å…³é”®å¸§æˆªå›¾ã€‚
- åªæœ‰åœ¨ç”»é¢ä¸­**æ˜ç¡®çœ‹åˆ°**çš„å…ƒç´ ï¼ˆå¦‚å…·ä½“çš„PPTæ–‡å­—ã€ä»£ç ç‰‡æ®µã€ç‰¹å®šçš„äººç‰©åŠ¨ä½œã€å›¾æ ‡ï¼‰æ‰èƒ½å†™å…¥æŠ¥å‘Šã€‚
- ç¦æ­¢è„‘è¡¥ç”»é¢ä¸­æ²¡æœ‰å‡ºç°çš„èƒŒæ™¯æˆ–ç»†èŠ‚ã€‚
"""
        
        danmaku_hint = ""
        if danmaku_content:
            danmaku_hint = f"""

ã€å¼¹å¹•å†…å®¹é¢„è§ˆã€‘
{danmaku_content[:500]}...
"""
        
        comments_hint = ""
        if content and 'ã€è§†é¢‘è¯„è®ºï¼ˆéƒ¨åˆ†ï¼‰ã€‘' in content:
             comments_hint = "\næˆ‘å·²ç»æä¾›äº†éƒ¨åˆ†ç²¾å½©è¯„è®ºå†…å®¹ï¼Œè¯·åœ¨ç¬¬ä¸‰æ¿å—è¿›è¡Œæ·±å…¥åˆ†æã€‚"

        return f"""ä½ æ˜¯ä¸€ä½ä¸¥è°¨çš„Bç«™è§†é¢‘åˆ†æä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯åŸºäºæˆ‘æä¾›çš„ç´ æç”Ÿæˆä¸€ä»½**å‡†ç¡®æ— è¯¯**çš„æŠ¥å‘Šã€‚

ã€åˆ†æå‡†åˆ™ - ä¸¥ç¦å¹»è§‰ã€‘
1. **ä»…é™ç´ æ**ï¼šæ‰€æœ‰ç»“è®ºå¿…é¡»ç›´æ¥æ¥æºäºæä¾›çš„ã€è§†é¢‘ä¿¡æ¯ã€‘ã€ã€è§†é¢‘å†…å®¹ï¼ˆå­—å¹•/æ–‡æ¡ˆï¼‰ã€‘ã€ã€å…³é”®å¸§ã€‘æˆ–ã€å¼¹å¹•è¯„è®ºã€‘ã€‚
2. **ç¦æ­¢æ¨æµ‹**ï¼šå¦‚æœç´ æä¸­æ²¡æœ‰æåˆ°æŸé¡¹æ•°æ®ï¼ˆå¦‚å…·ä½“æ”¶å…¥ã€æœªå…¬å¼€çš„æ—¥æœŸã€æœªæåŠçš„å“ç‰Œç­‰ï¼‰ï¼Œä¸¥ç¦ç¼–é€ ã€‚
3. **è§†è§‰ä¸€è‡´æ€§**ï¼šå¦‚æœå­—å¹•å†…å®¹ä¸ç”»é¢å†…å®¹å†²çªï¼Œä»¥ç”»é¢æ˜¾ç¤ºçš„æ–‡å­—/å®ç‰©ä¸ºå‡†ï¼Œå¹¶æ³¨æ˜ã€‚
4. **è¯šå®å‘ŠçŸ¥**ï¼šå¦‚æœæŸä¸ªåˆ†æç‚¹åœ¨ç´ æä¸­å®Œå…¨ç¼ºå¤±ï¼Œè¯·ç›´æ¥è·³è¿‡æˆ–è¯´æ˜â€œç´ ææœªæåŠâ€ã€‚

ã€è§†é¢‘åŸºæœ¬ä¿¡æ¯ã€‘
æ ‡é¢˜ï¼š{video_info.get('title', 'æœªçŸ¥')}
UPä¸»ï¼š{video_info.get('author', 'æœªçŸ¥')}
è§†é¢‘ç®€ä»‹ï¼š{video_info.get('desc', 'æ— ')}

ã€è§†é¢‘å®Œæ•´å†…å®¹ï¼ˆå­—å¹•/æ–‡æ¡ˆï¼‰ã€‘
{content[:Config.MAX_SUBTITLE_LENGTH]}{video_analysis_hint}{danmaku_hint}{comments_hint}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹**ä¸‰å¤§æ¿å—**æä¾›æ·±åº¦åˆ†ææŠ¥å‘Šï¼š
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

## ğŸ“‹ ç¬¬ä¸€æ¿å—ï¼šå†…å®¹æ·±åº¦æ€»ç»“ä¸åˆ†æ

### 1. è§†é¢‘æ ¸å¿ƒæ¦‚è§ˆ
- **æ ¸å¿ƒä¸»æ—¨**ï¼šç”¨ä¸€å¥è¯ç²¾å‡†æ¦‚æ‹¬è§†é¢‘ã€‚
- **ç›®æ ‡ä»·å€¼**ï¼šè§†é¢‘è§£å†³äº†ä»€ä¹ˆæ ¸å¿ƒé—®é¢˜ï¼Ÿä¸ºè§‚ä¼—æä¾›äº†ä»€ä¹ˆç‹¬ç‰¹ä»·å€¼ï¼ˆè®¤çŸ¥ã€æŠ€èƒ½ã€æƒ…æ„Ÿï¼‰ï¼Ÿ

### 2. ç»“æ„åŒ–å†…å®¹è¯¦è¿°
**è¦æ±‚**ï¼š
- æŒ‰è§†é¢‘é€»è¾‘é€»è¾‘ï¼Œ**ç²¾ç»†åŒ–**æå–æ ¸å¿ƒè®ºæ®ã€å…³é”®æ­¥éª¤ã€æ•°æ®æ”¯æ’‘å’Œå…¸å‹æ¡ˆä¾‹ã€‚
- åˆ†ç« èŠ‚è¿›è¡Œè¯¦å°½æ€»ç»“ï¼Œå­—æ•°éœ€å……å®ï¼Œä¸ä»…æ¦‚æ‹¬â€œè®²äº†ä»€ä¹ˆâ€ï¼Œæ›´è¦è§£é‡Šâ€œæ˜¯æ€ä¹ˆè®²çš„â€ä»¥åŠâ€œèƒŒåçš„é€»è¾‘â€ã€‚
- æ¯ä¸ªæ ¸å¿ƒè§‚ç‚¹è¯·é…åˆå¯¹åº”çš„è§†é¢‘äº‹å®è¿›è¡Œè®ºè¯ã€‚

### 3. å…³é”®çŸ¥è¯†ç‚¹ä¸æ·±åº¦è§è§£
- **äº‹å®ç½—åˆ—**ï¼šåˆ—å‡ºè§†é¢‘ä¸­æ˜ç¡®æåˆ°çš„çŸ¥è¯†ç‚¹æˆ–é‡è¦äº‹å®ã€‚
- **æ·±åº¦å»¶ä¼¸**ï¼šåŸºäºè§†é¢‘å†…å®¹ï¼Œåˆ†æå…¶åœ¨æ›´å¹¿é˜”èƒŒæ™¯ä¸‹çš„æ„ä¹‰ï¼Œæˆ–æä¾›è¡¥å……æ€§çš„èƒŒæ™¯çŸ¥è¯†ã€‚

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

## ğŸ’¬ ç¬¬äºŒæ¿å—ï¼šå¼¹å¹•äº’åŠ¨ä¸èˆ†æƒ…åˆ†æ
- **æ°›å›´æ´å¯Ÿ**ï¼šåˆ†æå¼¹å¹•çš„æƒ…ç»ªæ›²çº¿ï¼Œè¯†åˆ«è§‚ä¼—åœ¨å“ªä¸€æ—¶åˆ»åå“æœ€çƒ­çƒˆã€‚
- **é«˜é¢‘è¯äº‘**ï¼šæå–çœŸå®çš„é‡å¤å…³é”®è¯æ±‡ï¼Œå¹¶è§£è¯»èƒŒåçš„è§‚ä¼—å¿ƒç†ã€‚
- **äº’åŠ¨æ§½ç‚¹**ï¼šæ•æ‰è§†é¢‘ä¸­çš„â€œæ¢—â€ã€äº‰è®®ç‚¹æˆ–å…±é¸£ç‚¹ã€‚

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

## ğŸ“ ç¬¬ä¸‰æ¿å—ï¼šè¯„è®ºåŒºæ·±åº¦è§£æä¸å»ºè®®
- **è¯„è®ºç”»åƒ**ï¼šåˆ†æé«˜èµè¯„è®ºçš„æ„æˆï¼Œè§‚ä¼—æ˜¯åœ¨è¡¥å……å¹²è´§ã€è¡¨è¾¾æ„Ÿè°¢è¿˜æ˜¯è¿›è¡Œç†æ€§è®¨è®ºï¼Ÿ
- **ç²¾é€‰è§£è¯»**ï¼šæ·±å…¥åˆ†ææä¾›çš„ç²¾å½©è¯„è®ºï¼Œæå–å…¶ä¸­æœ€æœ‰ä»·å€¼çš„è§‚ç‚¹æˆ–çº é”™ä¿¡æ¯ã€‚
- **åç»­ä¼˜åŒ–å»ºè®®**ï¼šåŸºäºç›®å‰çš„è§‚ä¼—åé¦ˆï¼Œä¸ºUPä¸»æä¾›å…·ä½“å¯æ‰§è¡Œçš„æ”¹è¿›æ–¹æ¡ˆæˆ–æ–°é€‰é¢˜çµæ„Ÿã€‚

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

**è¾“å‡ºæ ¼å¼**ï¼š
- ä½¿ç”¨Markdownï¼Œå¤šç”¨ Emojiã€‚
- ä¿æŒä¸“ä¸šã€å®¢è§‚çš„è¯­æ°”ã€‚
- å¦‚æœä¿¡æ¯ä¸è¶³ä»¥æ”¯æ’‘æŸä¸ªå­æ ‡é¢˜ï¼Œè¯·åˆ é™¤è¯¥æ ‡é¢˜ã€‚"""

    
    def _extract_content(self, response) -> str:
        """æå–å“åº”å†…å®¹ï¼Œå…¼å®¹ä¸åŒAPIæ ¼å¼"""
        try:
            print(f"[è°ƒè¯•] _extract_content - å“åº”ç±»å‹: {type(response)}")
            
            # å°è¯•æ ‡å‡†OpenAIæ ¼å¼
            if hasattr(response, 'choices') and response.choices:
                content = response.choices[0].message.content
                print(f"[è°ƒè¯•] æå–åˆ°å†…å®¹é•¿åº¦: {len(content) if content else 0}")
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯HTMLï¼ˆé”™è¯¯å“åº”ï¼‰
                if content and content.strip().startswith('<!doctype') or content.strip().startswith('<html'):
                    raise ValueError("APIè¿”å›äº†HTMLé¡µé¢è€Œä¸æ˜¯æ–‡æœ¬å†…å®¹ï¼Œè¯·æ£€æŸ¥APIé…ç½®å’Œç½‘ç»œè¿æ¥")
                
                return content
            
            # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œç›´æ¥è¿”å›
            if isinstance(response, str):
                # æ£€æŸ¥æ˜¯å¦æ˜¯HTML
                if response.strip().startswith('<!doctype') or response.strip().startswith('<html'):
                    raise ValueError("APIè¿”å›äº†HTMLé¡µé¢ï¼Œè¯·æ£€æŸ¥OPENAI_API_BASEé…ç½®")
                return response
            
            # å¦‚æœæ˜¯å­—å…¸ï¼Œå°è¯•æå–å†…å®¹
            if isinstance(response, dict):
                if 'choices' in response and response['choices']:
                    return response['choices'][0]['message']['content']
                if 'content' in response:
                    return response['content']
                if 'text' in response:
                    return response['text']
                # å¦‚æœå­—å…¸ä¸­æœ‰error
                if 'error' in response:
                    raise ValueError(f"APIè¿”å›é”™è¯¯: {response['error']}")
            
            # å°è¯•è½¬æ¢ä¸ºå­—ç¬¦ä¸²
            result = str(response)
            print(f"[è­¦å‘Š] å“åº”æ ¼å¼æœªçŸ¥ï¼Œè½¬ä¸ºå­—ç¬¦ä¸²: {result[:200]}")
            return result
        except Exception as e:
            print(f"[é”™è¯¯] æå–å†…å®¹å¤±è´¥: {str(e)}, å“åº”ç±»å‹: {type(response)}")
            raise
    
    def _extract_tokens(self, response) -> int:
        """æå–tokenä½¿ç”¨é‡ï¼Œå…¼å®¹ä¸åŒAPIæ ¼å¼"""
        try:
            if hasattr(response, 'usage') and response.usage:
                if hasattr(response.usage, 'total_tokens'):
                    return response.usage.total_tokens
            
            if isinstance(response, dict):
                if 'usage' in response:
                    return response['usage'].get('total_tokens', 0)
            
            return 0
        except Exception as e:
            print(f"[è­¦å‘Š] æå–tokenså¤±è´¥: {str(e)}")
            return 0
    
    def _parse_analysis_response(self, analysis_text: str) -> Dict:
        """è§£æåˆ†æå“åº”ï¼Œæå–ç»“æ„åŒ–å†…å®¹"""
        sections = {
            'summary': '',
            'danmaku': '',
            'comments': ''
        }
        
        current_section = None
        lines = analysis_text.split('\n')
        
        for line in lines:
            line_lower = line.lower()
            # åŒ¹é…ç¬¬ä¸€æ¿å—ï¼šå†…å®¹æ€»ç»“
            if 'å†…å®¹æ·±åº¦æ€»ç»“' in line or 'ç¬¬ä¸€æ¿å—' in line:
                current_section = 'summary'
            # åŒ¹é…ç¬¬äºŒæ¿å—ï¼šå¼¹å¹•åˆ†æ
            elif 'å¼¹å¹•äº’åŠ¨' in line or 'ç¬¬äºŒæ¿å—' in line or 'èˆ†æƒ…åˆ†æ' in line:
                current_section = 'danmaku'
            # åŒ¹é…ç¬¬ä¸‰æ¿å—ï¼šè¯„è®ºåˆ†æ
            elif 'è¯„è®ºåŒºæ·±åº¦' in line or 'ç¬¬ä¸‰æ¿å—' in line or 'è¯„è®ºè§£æ' in line:
                current_section = 'comments'
            elif current_section:
                sections[current_section] += line + '\n'
        
        return sections

