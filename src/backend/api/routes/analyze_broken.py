"""
è§†é¢‘åˆ†æè·¯ç”±æ¨¡å—
æä¾›è§†é¢‘åˆ†æã€æ™ºèƒ½å°UPå’Œå¯¹è¯é—®ç­”æ¥å£
"""
import asyncio
import json
from flask import request, jsonify, Response
from src.backend.utils.logger import get_logger
from src.backend.utils.validators import validate_question_input, validate_json_data, validate_bvid, ValidationError
from src.backend.utils.error_handler import ErrorResponse, handle_errors

logger = get_logger(__name__)


def init_analyze_routes(app, bilibili_service, ai_service):
    """
    åˆå§‹åŒ–åˆ†æç›¸å…³è·¯ç”±

    Args:
        app: Flask åº”ç”¨å®ä¾‹
        bilibili_service: BilibiliService å®ä¾‹
        ai_service: AIService å®ä¾‹
    """
    from src.backend.services.bilibili import BilibiliService, run_async

    @app.route('/api/smart_up/stream', methods=['POST'])
    @handle_errors
    def smart_up_stream():
        """æ™ºèƒ½å°UP å¿«é€Ÿé—®ç­”æµ"""
        # éªŒè¯è¾“å…¥
        data = validate_json_data(request.json, required_fields=['question'])
        question = validate_question_input(data.get('question'))
        history = data.get('history', [])

        def generate():
            try:
                for chunk in ai_service.smart_up_stream(question, bilibili_service, history):
                    yield f"data: {json.dumps(chunk, ensure_ascii=False)}\n\n"
            except Exception as e:
                logger.error(f"æ™ºèƒ½å°UPæµå¼è¾“å‡ºé”™è¯¯: {str(e)}")
                yield ErrorResponse.sse_error(f"åˆ†æè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")

        return Response(generate(), mimetype='text/event-stream')

    @app.route('/api/chat/stream', methods=['POST'])
    @handle_errors
    def chat_video_stream():
        """è§†é¢‘å†…å®¹æµå¼é—®ç­”"""
        # éªŒè¯è¾“å…¥
        data = validate_json_data(request.json, required_fields=['question', 'context'])
        question = validate_question_input(data.get('question'))
        context = validate_question_input(data.get('context'))
        video_info = data.get('video_info', {})
        history = data.get('history', [])

        def generate():
            try:
                for chunk in ai_service.chat_stream(question, context, video_info, history):
                    yield f"data: {json.dumps(chunk, ensure_ascii=False)}\n\n"
            except Exception as e:
                logger.error(f"è§†é¢‘å¯¹è¯æµå¼è¾“å‡ºé”™è¯¯: {str(e)}")
                yield ErrorResponse.sse_error(f"å¯¹è¯è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")

        return Response(generate(), mimetype='text/event-stream')

    @app.route('/api/analyze', methods=['POST'])
    @handle_errors
    def analyze_video():
        """åˆ†æè§†é¢‘çš„ä¸»æ¥å£"""
        # éªŒè¯è¾“å…¥
        data = validate_json_data(request.json, required_fields=['url'])
        url = data.get('url', '')

        # æå–BVID
        try:
            bvid = validate_bvid(url)
        except ValidationError as e:
            logger.error(f"æ— æ•ˆçš„Bç«™é“¾æ¥: {url}")
            return jsonify(ErrorResponse.error(str(e), error_code="INVALID_URL", status_code=400)[0]), 400

            # è·å–è§†é¢‘ä¿¡æ¯
            video_info_result = run_async(bilibili_service.get_video_info(bvid))
            if not video_info_result['success']:
                return jsonify(video_info_result), 400

            video_info = video_info_result['data']

            # è·å–å­—å¹•
            logger.info("å¼€å§‹è·å–å­—å¹•...")
            subtitle_result = run_async(bilibili_service.get_video_subtitles(bvid))

            # è·å–å¼¹å¹•ï¼ˆç”¨äºåˆ†æï¼‰
            logger.info("å¼€å§‹è·å–å¼¹å¹•...")
            danmaku_result = run_async(bilibili_service.get_video_danmaku(bvid, limit=200))
            danmaku_texts = []
            if danmaku_result['success']:
                danmaku_texts = danmaku_result['data']['danmakus']
                logger.info("è·å–åˆ° {} æ¡å¼¹å¹•".format(len(danmaku_texts)))

            # è·å–è¯„è®ºï¼ˆç”¨äºåˆ†æï¼‰
            logger.info("å¼€å§‹è·å–è¯„è®º...")
            comments_result = run_async(bilibili_service.get_video_comments(bvid, max_pages=10))
            comments_data = []
            if comments_result['success']:
                comments_data = comments_result['data']['comments']
                logger.info("è·å–åˆ° {} æ¡è¯„è®º".format(len(comments_data)))

            # è·å–ç»Ÿè®¡æ•°æ®
            logger.info("å¼€å§‹è·å–ç»Ÿè®¡æ•°æ®...")
            stats_result = run_async(bilibili_service.get_video_stats(bvid))
            stats_data = stats_result['data'] if stats_result['success'] else {}

            # æ„å»ºå†…å®¹
            content = ''
            has_subtitle = False

            if subtitle_result['success'] and subtitle_result['data'].get('has_subtitle'):
                content = subtitle_result['data']['full_text']
                has_subtitle = True
                logger.info("ä½¿ç”¨å­—å¹•ä½œä¸ºä¸»è¦å†…å®¹ï¼ˆ{}å­—ï¼‰".format(len(content)))
            else:
                # ä½¿ç”¨å¼¹å¹•å’Œç®€ä»‹
                if danmaku_texts:
                    content = '\n'.join(danmaku_texts)
                    content = f"ã€è§†é¢‘ç®€ä»‹ã€‘\n{video_info.get('desc', '')}\n\nã€å¼¹å¹•å†…å®¹ã€‘\n{content}"
                    logger.info("ä½¿ç”¨å¼¹å¹•ä½œä¸ºå†…å®¹ï¼ˆ{}æ¡ï¼‰".format(len(danmaku_texts)))
                else:
                    content = f"ã€è§†é¢‘ç®€ä»‹ã€‘\n{video_info.get('desc', '')}"

            if not content or len(content) < 50:
                return jsonify({
                    'success': False,
                    'error': 'æ— æ³•è·å–è§†é¢‘å†…å®¹ï¼ˆæ— å­—å¹•ä¸”æ— æœ‰æ•ˆå¼¹å¹•ï¼‰'
                }), 400

            # è·å–è§†é¢‘å¸§è¿›è¡Œå¤šæ¨¡æ€åˆ†æ
            logger.info("å¼€å§‹æå–è§†é¢‘å…³é”®å¸§...")
            frames_result = run_async(bilibili_service.extract_video_frames(bvid))

            video_frames = None
            if frames_result['success']:
                video_frames = frames_result['data']['frames']
                logger.info("æˆåŠŸæå– {} å¸§ç”»é¢".format(len(video_frames)))
            else:
                logger.warning("è§†é¢‘å¸§æå–å¤±è´¥: {}".format(frames_result['error']))
                logger.info("ğŸ“ å°†ä»…ä½¿ç”¨æ–‡æœ¬å†…å®¹è¿›è¡Œåˆ†æ")

            # è°ƒç”¨AIç”Ÿæˆåˆ†æ
            analysis_result = ai_service.generate_full_analysis(video_info, content, video_frames)

            if not analysis_result['success']:
                return jsonify(analysis_result), 500

            # è¿”å›å®Œæ•´ç»“æœ
            return jsonify({
                'success': True,
                'data': {
                    'video_info': video_info,
                    'stats': stats_data,
                    'has_subtitle': has_subtitle,
                    'has_video_frames': bool(video_frames),
                    'frame_count': len(video_frames) if video_frames else 0,
                    'content': content,
                    'content_length': len(content),
                    'danmaku_count': len(danmaku_texts),
                    'comment_count': len(comments_data),
                    'danmaku_preview': danmaku_texts[:20] if danmaku_texts else [],
                    'comments_preview': comments_data[:10] if comments_data else [],
                    'analysis': analysis_result['data']['full_analysis'],
                    'parsed': analysis_result['data']['parsed'],
                    'tokens_used': analysis_result['data']['tokens_used']
                }
            })

        except Exception as e:
            return jsonify({
                'success': False,
                'error': f'æœåŠ¡å™¨é”™è¯¯: {str(e)}'
            }), 500

    @app.route('/api/analyze/stream', methods=['POST'])
    def analyze_video_stream():
        """æµå¼åˆ†ææ¥å£ï¼Œæ”¯æŒè§†é¢‘ (BV)ã€ä¸“æ  (CV) åŠåŠ¨æ€ (Opus)"""
        try:
            data = request.get_json()
            url = data.get('url', '')

            if not url:
                return jsonify({'success': False, 'error': 'è¯·æä¾›Bç«™è§†é¢‘æˆ–ä¸“æ é“¾æ¥'}), 400

            # å°è¯•æå–å„ç§ ID
            bvid = BilibiliService.extract_bvid(url)
            article_meta = BilibiliService.extract_article_id(url)

            def generate_stream():
                try:
                    nonlocal bvid, article_meta

                    # æ™ºèƒ½æœç´¢é€»è¾‘ï¼šå¦‚æœè¾“å…¥çš„ä¸æ˜¯ IDï¼Œåˆ™è§†ä¸ºå…³é”®è¯æœç´¢
                    if not bvid and not article_meta:
                        yield f"data: {json.dumps({'type': 'stage', 'stage': 'searching', 'message': f'æ­£åœ¨ä¸ºæ‚¨æœç´¢ç›¸å…³å†…å®¹...', 'progress': 5})}\n\n"

                        mode = data.get('mode', 'video')

                        if mode == 'article':
                            search_res = run_async(bilibili_service.search_articles(url, limit=1))
                            if search_res['success'] and search_res['data']:
                                article_meta = {'type': 'cv', 'id': search_res['data'][0]['cvid']}
                                yield f"data: {json.dumps({'type': 'stage', 'stage': 'search_complete', 'message': f'ä¸ºæ‚¨æ‰¾åˆ°ä¸“æ : {search_res['data'][0]['title']}', 'progress': 10})}\n\n"
                            else:
                                yield f"data: {json.dumps({'type': 'error', 'error': 'æœªæ‰¾åˆ°ç›¸å…³ä¸“æ å†…å®¹'})}\n\n"
                                return
                        else:
                            search_res = run_async(bilibili_service.search_videos(url, limit=1))
                            if search_res['success'] and search_res['data']:
                                bvid = search_res['data'][0]['bvid']
                                yield f"data: {json.dumps({'type': 'stage', 'stage': 'search_complete', 'message': f'ä¸ºæ‚¨æ‰¾åˆ°è§†é¢‘: {search_res['data'][0]['title']}', 'progress': 10})}\n\n"
                            else:
                                yield f"data: {json.dumps({'type': 'error', 'error': 'æœªæ‰¾åˆ°ç›¸å…³è§†é¢‘'})}\n\n"
                                return

                    # ä¸“æ  / Opus åˆ†æé€»è¾‘
                    if article_meta:
                        a_type = article_meta['type']
                        a_id = article_meta['id']

                        yield f"data: {json.dumps({'type': 'stage', 'stage': 'fetching_info', 'message': f'è·å–{a_type}ä¿¡æ¯...', 'progress': 10})}\n\n"

                        if a_type == 'cv':
                            res = run_async(bilibili_service.get_article_content(a_id))
                        else:
                            res = run_async(bilibili_service.get_opus_content(a_id))

                        if not res['success']:
                            yield f"data: {json.dumps({'type': 'error', 'error': res['error']})}\n\n"
                            return

                        yield f"data: {json.dumps({'type': 'stage', 'stage': 'info_complete', 'message': f'å·²è·å–å†…å®¹: {res['data']['title']}', 'progress': 20, 'info': res['data']})}\n\n"
                        yield f"data: {json.dumps({'type': 'stage', 'stage': 'starting_analysis', 'message': 'æ­£åœ¨æ·±åº¦è§£æå†…å®¹...', 'progress': 40})}\n\n"

                        article_full_content = res['data']['content']
                        article_res_data = res['data']

                        for chunk in ai_service.generate_article_analysis_stream(res['data'], res['data']['content']):
                            yield f"data: {json.dumps(chunk, ensure_ascii=False)}\n\n"

                        yield f"data: {json.dumps({
                            'type': 'final',
                            'stage': 'completed',
                            'message': 'ä¸“æ åˆ†æå®Œæˆï¼',
                            'progress': 100,
                            'content': article_full_content,
                            'info': article_res_data
                        }, ensure_ascii=False)}\n\n"
                        return

                    # è§†é¢‘åˆ†æé€»è¾‘
                    yield f"data: {json.dumps({'type': 'stage', 'stage': 'fetching_info', 'message': 'è·å–è§†é¢‘ä¿¡æ¯...', 'progress': 5})}\n\n"
                    video_info_result = run_async(bilibili_service.get_video_info(bvid))
                    if not video_info_result['success']:
                        yield f"data: {json.dumps({'type': 'error', 'error': video_info_result['error']})}\n\n"
                        return

                    video_info = video_info_result['data']
                    video_title = video_info.get('title', '')
                    yield f"data: {json.dumps({'type': 'stage', 'stage': 'info_complete', 'message': f'å·²è·å–è§†é¢‘ä¿¡æ¯: {video_title}', 'progress': 15})}\n\n"

                    # é˜¶æ®µ2: è·å–å†…å®¹æ•°æ®
                    yield f"data: {json.dumps({'type': 'stage', 'stage': 'fetching_content', 'message': 'è·å–å­—å¹•å’Œå¼¹å¹•...', 'progress': 20})}\n\n"

                    tasks = [
                        bilibili_service.get_video_subtitles(bvid),
                        bilibili_service.get_video_danmaku(bvid, limit=1000),
                        bilibili_service.get_video_comments(bvid, max_pages=30, target_count=500),
                        bilibili_service.get_video_stats(bvid)
                    ]

                    results = run_async(asyncio.gather(*tasks, return_exceptions=True))
                    subtitle_result, danmaku_result, comments_result, stats_result = results

                    # å¤„ç†å¼¹å¹•æ•°æ®
                    danmaku_texts = []
                    if danmaku_result and hasattr(danmaku_result, 'get') and danmaku_result.get('success'):
                        danmaku_texts = danmaku_result['data']['danmakus']

                    # å¤„ç†è¯„è®ºæ•°æ®
                    comments_data = []
                    if comments_result and hasattr(comments_result, 'get') and comments_result.get('success'):
                        comments_data = comments_result['data']['comments']

                    # å¤„ç†ç»Ÿè®¡æ•°æ®
                    stats_data = stats_result['data'] if stats_result and hasattr(stats_result, 'get') and stats_result.get('success') else {}

                    # æ„å»ºå†…å®¹
                    content = ''
                    has_subtitle = False

                    if subtitle_result and hasattr(subtitle_result, 'get') and subtitle_result.get('success') and subtitle_result['data'].get('has_subtitle'):
                        content = subtitle_result['data']['full_text']
                        has_subtitle = True
                        text_source = "å­—å¹•"

                        extra_context = ""
                        if danmaku_texts:
                            extra_context += f"\n\nã€å¼¹å¹•å†…å®¹ï¼ˆéƒ¨åˆ†ï¼‰ã€‘\n" + "\n".join(danmaku_texts[:100])
                        if comments_data:
                            comment_texts = [f"{c['username']}: {c['message']}" for c in comments_data[:50]]
                            extra_context += f"\n\nã€è§†é¢‘è¯„è®ºï¼ˆéƒ¨åˆ†ï¼‰ã€‘\n" + "\n".join(comment_texts)

                        content += extra_context
                        yield f"data: {json.dumps({'type': 'stage', 'stage': 'content_ready', 'message': 'ä½¿ç”¨å­—å¹•å†…å®¹ï¼ˆ{}å­—ï¼‰'.format(len(content)), 'progress': 35, 'content': content, 'has_subtitle': True, 'text_source': text_source})}\n\n"
                    else:
                        text_source = "æ–‡æ¡ˆ"
                        base_content = f"ã€è§†é¢‘ç®€ä»‹ã€‘\n{video_info.get('desc', '')}"
                        if danmaku_texts:
                            base_content += f"\n\nã€å¼¹å¹•å†…å®¹ã€‘\n" + "\n".join(danmaku_texts)
                        if comments_data:
                            comment_texts = [f"{c['username']}: {c['message']}" for c in comments_data]
                            base_content += f"\n\nã€è§†é¢‘è¯„è®ºã€‘\n" + "\n".join(comment_texts)

                        content = base_content
                        yield f"data: {json.dumps({'type': 'stage', 'stage': 'content_ready', 'message': 'ä½¿ç”¨è§†é¢‘æ–‡æ¡ˆè¿›è¡Œåˆ†æ', 'progress': 35, 'content': content, 'has_subtitle': False, 'text_source': text_source})}\n\n"

                    if not content or len(content) < 50:
                        yield f"data: {json.dumps({'type': 'error', 'error': 'æ— æ³•è·å–è§†é¢‘å†…å®¹ï¼ˆæ— å­—å¹•ä¸”æ— æœ‰æ•ˆå¼¹å¹•ï¼‰'})}\n\n"
                        return

                    # é˜¶æ®µ3: æå–è§†é¢‘å¸§
                    yield f"data: {json.dumps({'type': 'stage', 'stage': 'extracting_frames', 'message': 'æå–è§†é¢‘å…³é”®å¸§...', 'progress': 40})}\n\n"

                    frames_result = run_async(bilibili_service.extract_video_frames(bvid))
                    video_frames = None
                    frame_count = 0

                    if frames_result and frames_result.get('success'):
                        video_frames = frames_result['data']['frames']
                        frame_count = len(video_frames)
                        yield f"data: {json.dumps({'type': 'stage', 'stage': 'frames_ready', 'message': 'æˆåŠŸæå– {} å¸§ç”»é¢'.format(frame_count), 'progress': 50, 'has_frames': True, 'frame_count': frame_count})}\n\n"
                    else:
                        yield f"data: {json.dumps({'type': 'stage', 'stage': 'frames_ready', 'message': 'å°†ä»…ä½¿ç”¨æ–‡æœ¬å†…å®¹è¿›è¡Œåˆ†æ', 'progress': 50, 'has_frames': False, 'frame_count': 0})}\n\n"

                    # é˜¶æ®µ4: å¼€å§‹AIåˆ†æï¼ˆæµå¼ï¼‰
                    yield f"data: {json.dumps({'type': 'stage', 'stage': 'starting_analysis', 'message': 'å¼€å§‹AIæ™ºèƒ½åˆ†æ...', 'progress': 55})}\n\n"

                    for chunk in ai_service.generate_full_analysis_stream(video_info, content, video_frames):
                        chunk_json = json.dumps(chunk, ensure_ascii=False)
                        yield f"data: {chunk_json}\n\n"

                    # å‘é€æœ€ç»ˆå®Œæ•´ç»“æœ
                    top_comments = []
                    comments_count = len(comments_data) if comments_data else 0
                    danmaku_count = len(danmaku_texts) if danmaku_texts else 0

                    if comments_data:
                        sorted_comments = sorted(comments_data, key=lambda x: x.get('like', 0), reverse=True)
                        top_comments = sorted_comments[:8]

                    login_info = " (å·²ç™»å½•)" if bilibili_service.credential else " (æœªç™»å½•)"
                    yield f"data: {json.dumps({
                        'type': 'final',
                        'stage': 'completed',
                        'message': f'åˆ†æå®Œæˆï¼{login_info}',
                        'progress': 100,
                        'content': content,
                        'top_comments': top_comments,
                        'danmaku_preview': danmaku_texts[:200] if danmaku_texts else [],
                        'frame_count': frame_count,
                        'comments_count': comments_count,
                        'danmaku_count': danmaku_count
                    })}\n\n"

                except Exception as e:
                    logger.error("æµå¼åˆ†æå¼‚å¸¸: {}".format(str(e)))
                    import traceback
                    traceback.print_exc()
                    yield f"data: {json.dumps({'type': 'error', 'error': f'åˆ†æè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}'})}\n\n"

            return Response(
                generate_stream(),
                mimetype='text/event-stream',
                headers={
                    'Cache-Control': 'no-cache',
                    'Connection': 'keep-alive',
                    'Access-Control-Allow-Origin': '*',
                    'Access-Control-Allow-Headers': 'Cache-Control'
                }
            )

        except Exception as e:
            return jsonify({
                'success': False,
                'error': f'æœåŠ¡å™¨é”™è¯¯: {str(e)}'
            }), 500
