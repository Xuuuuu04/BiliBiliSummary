"""
æ·±åº¦ç ”ç©¶ Agentæ¨¡å—
æä¾›å…¨æ–¹ä½æ·±åº¦è°ƒç ”å’ŒæŠ¥å‘Šæ’°å†™åŠŸèƒ½
"""
import json
import asyncio
from typing import Generator, Dict
from openai import OpenAI
from src.config import Config
from src.backend.services.ai.prompts import get_deep_research_system_prompt, get_video_analysis_prompt
from src.backend.services.ai.ai_helpers import web_search_exa, save_research_report
from src.backend.utils.async_helpers import run_async
from src.backend.utils.logger import get_logger
from src.backend.services.ai.toolkit import ToolRegistry
from src.backend.services.ai.toolkit.tools import (
    SearchVideosTool,
    AnalyzeVideoTool,
    WebSearchTool,
    SearchUsersTool,
    GetUserRecentVideosTool,
    FinishResearchTool
)

logger = get_logger(__name__)


class DeepResearchAgent:
    """
    æ·±åº¦ç ”ç©¶ Agent

    é’ˆå¯¹è¯¾é¢˜è¿›è¡Œå…¨æ–¹ä½æ·±åº¦è°ƒç ”ï¼Œæ’°å†™ä¸“ä¸šç ”ç©¶æŠ¥å‘Š
    """

    def __init__(self, client: OpenAI, model: str, vl_model: str = None, enable_thinking: bool = False):
        """
        åˆå§‹åŒ–æ·±åº¦ç ”ç©¶ Agent

        Args:
            client: OpenAIå®¢æˆ·ç«¯
            model: ä½¿ç”¨çš„æ¨¡å‹ï¼ˆæ·±åº¦ç ”ç©¶ï¼‰
            vl_model: è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆå¯é€‰ï¼Œç”¨äºè§†é¢‘å¸§åˆ†æï¼‰
            enable_thinking: æ˜¯å¦å¯ç”¨æ€è€ƒæ¨¡å¼ï¼ˆç”¨äºæ”¯æŒthinkingçš„æ··åˆæ€æ¨¡å‹ï¼‰
        """
        self.client = client
        self.model = model
        self.vl_model = vl_model or model  # å¦‚æœæœªæŒ‡å®šï¼Œä½¿ç”¨æ™®é€šæ¨¡å‹
        self.enable_thinking = enable_thinking

        # åˆå§‹åŒ–å·¥å…·æ³¨å†Œä¸­å¿ƒ
        self._initialize_tools()

    def _initialize_tools(self):
        """åˆå§‹åŒ–å¹¶æ³¨å†Œæ‰€æœ‰å·¥å…·"""
        # æ¸…ç©ºä¹‹å‰çš„æ³¨å†Œ
        ToolRegistry.clear()

        # æ³¨å†Œæ ¸å¿ƒå·¥å…·
        tools = [
            SearchVideosTool(),
            AnalyzeVideoTool(),
            WebSearchTool(),
            SearchUsersTool(),
            GetUserRecentVideosTool(),
            FinishResearchTool()
        ]

        for tool in tools:
            ToolRegistry.register(tool)
            # è®¾ç½®AIå®¢æˆ·ç«¯
            tool.set_ai_client(self.client, self.model)

        logger.info(f"[DeepResearchAgent] å·²æ³¨å†Œ {ToolRegistry.count()} ä¸ªå·¥å…·")

    def stream_research(self, topic: str, bilibili_service) -> Generator[Dict, None, None]:
        """
        æµå¼æ·±åº¦ç ”ç©¶

        Args:
            topic: ç ”ç©¶è¯¾é¢˜
            bilibili_service: Bç«™æœåŠ¡å®ä¾‹

        Yields:
            Dict: åŒ…å«çŠ¶æ€ã€è¿›åº¦ã€å†…å®¹ç­‰ä¿¡æ¯çš„å­—å…¸
        """
        try:
            # è®¾ç½®å·¥å…·çš„bilibili_service
            ToolRegistry.set_services(bilibili_service=bilibili_service)

            system_prompt = get_deep_research_system_prompt(topic)

            tools = self._get_tools_definition()

            messages = [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": f"è¯·é’ˆå¯¹ä»¥ä¸‹è¯¾é¢˜å¼€å§‹æ·±åº¦ç ”ç©¶ï¼š{topic}"}
            ]

            # æœ€å¤§è½®æ¬¡é™åˆ¶ï¼Œé˜²æ­¢æ— é™å¾ªç¯
            max_rounds = 100  # æ·±åº¦ç ”ç©¶æå‡è‡³100è½®
            round_count = 0

            for _ in range(max_rounds):
                round_count += 1
                yield {'type': 'round_start', 'round': round_count}

                # æ„å»ºAPIè¯·æ±‚å‚æ•°
                request_params = {
                    "model": self.model,
                    "messages": messages,
                    "tools": tools,
                    "tool_choice": "auto",
                    "stream": True
                }

                # å¦‚æœå¯ç”¨æ€è€ƒæ¨¡å¼ï¼Œæ·»åŠ é¢å¤–å‚æ•°
                # æ³¨æ„ï¼šåªæœ‰éƒ¨åˆ†æ¨¡å‹ï¼ˆå¦‚DeepSeek-V3ã€Kimi-K2ï¼‰æ”¯æŒè¿™äº›å‚æ•°
                if self.enable_thinking:
                    # å¯¹äºæ”¯æŒçš„æ¨¡å‹ï¼Œå¯ç”¨æ€è€ƒæ¨¡å¼é€šå¸¸ä¸éœ€è¦é¢å¤–å‚æ•°
                    # æ¨¡å‹ä¼šè‡ªåŠ¨è¿”å› reasoning_content å­—æ®µ
                    pass  # æŸäº›æ¨¡å‹å¯èƒ½éœ€è¦é¢å¤–çš„ max_tokens ç­‰å‚æ•°

                stream = self.client.chat.completions.create(**request_params)

                tool_calls = []
                full_content = ""

                # å¤„ç†æµå¼å“åº”
                for chunk in stream:
                    if not chunk.choices:
                        continue
                    delta = chunk.choices[0].delta

                    # å¤„ç†æ€è€ƒè¿‡ç¨‹
                    if hasattr(delta, 'reasoning_content') and delta.reasoning_content:
                        yield {'type': 'thinking', 'content': delta.reasoning_content}

                    if delta.content:
                        full_content += delta.content
                        yield {'type': 'content', 'content': delta.content}

                    if delta.tool_calls:
                        for tool_call in delta.tool_calls:
                            if len(tool_calls) <= tool_call.index:
                                tool_calls.append({
                                    "id": tool_call.id,
                                    "type": "function",
                                    "function": {"name": "", "arguments": ""}
                                })
                            if tool_call.id:
                                tool_calls[tool_call.index]["id"] = tool_call.id
                            if tool_call.function.name:
                                tool_calls[tool_call.index]["function"]["name"] += tool_call.function.name
                            if tool_call.function.arguments:
                                tool_calls[tool_call.index]["function"]["arguments"] += tool_call.function.arguments

                # æ£€æµ‹æ˜¯å¦æ‰€æœ‰çš„å·¥å…·è°ƒç”¨éƒ½æ˜¯ analyze_videoï¼ˆç”¨äºæ™ºèƒ½å¹¶è¡Œæ‰§è¡Œï¼‰
                batch_analyze_detected = False
                if tool_calls and len(tool_calls) > 1:
                    analyze_video_calls = [tc for tc in tool_calls if tc.get("function", {}).get("name") == "analyze_video"]

                    # å¦‚æœæ‰€æœ‰çš„å·¥å…·è°ƒç”¨éƒ½æ˜¯ analyze_videoï¼Œåˆ™å¹¶è¡Œæ‰§è¡Œ
                    if len(analyze_video_calls) == len(tool_calls) and len(analyze_video_calls) > 1:
                        batch_analyze_detected = True
                        logger.info(f"[æ™ºèƒ½å¹¶è¡Œ] æ£€æµ‹åˆ° {len(analyze_video_calls)} ä¸ª analyze_video è°ƒç”¨ï¼Œå°†å¹¶è¡Œæ‰§è¡Œ")

                # å¦‚æœæ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œè¯´æ˜ç ”ç©¶å®Œæˆæˆ–æ¨¡å‹ç›´æ¥ç»™å‡ºäº†ç»“è®º
                if not tool_calls:
                    # æ ¸å¿ƒä¿®å¤ï¼šå¦‚æœæ¨¡å‹ç›´æ¥ç»™å‡ºäº†å†…å®¹ä½†æ²¡æœ‰è°ƒç”¨ finish å·¥å…·
                    if not any(msg.get('role') == 'tool' and msg.get('name') == 'finish_research_and_write_report' for msg in messages):
                        if round_count < max_rounds:
                            messages.append({"role": "assistant", "content": full_content})
                            messages.append({
                                "role": "user",
                                "content": "ç ”ç©¶å°šæœªç»“æŸã€‚è¯·ç»§ç»­ä½¿ç”¨å·¥å…·ï¼ˆå¦‚æœç´¢ç›¸å…³è§†é¢‘ã€åˆ†æè§†é¢‘ã€æœç´¢UPä¸»æˆ–ä½œå“é›†ï¼‰è¿›è¡Œæ·±å…¥è°ƒç ”ã€‚åªæœ‰å½“ä½ è®¤ä¸ºèµ„æ–™å®Œå…¨å……è¶³æ—¶ï¼Œè¯·ã€åŠ¡å¿…è°ƒç”¨ã€‘`finish_research_and_write_report` å·¥å…·æ¥å¯åŠ¨æ­£å¼æŠ¥å‘Šçš„æ’°å†™ã€‚ä¸è¦ç›´æ¥åœ¨å¯¹è¯ä¸­ç»“æŸã€‚"
                            })
                            continue
                    messages.append({"role": "assistant", "content": full_content})
                    break

                # å¤„ç†å·¥å…·è°ƒç”¨
                messages.append({
                    "role": "assistant",
                    "content": full_content,
                    "tool_calls": tool_calls
                })

                # å¦‚æœæ£€æµ‹åˆ°æ‰¹é‡ analyze_video è°ƒç”¨ï¼Œæ‰§è¡Œæ™ºèƒ½å¹¶è¡Œ
                if batch_analyze_detected:
                    yield {'type': 'batch_analyze_start', 'count': len(tool_calls)}

                    # å¹¶è¡Œæ‰§è¡Œæ‰€æœ‰è§†é¢‘åˆ†æ
                    from asyncio import gather

                    def analyze_single_video(bvid):
                        """åˆ†æå•ä¸ªè§†é¢‘ï¼ˆå¤ç”¨ç°æœ‰é€»è¾‘ï¼‰- åŒæ­¥ç‰ˆæœ¬"""
                        # æ¸…ç†BVID
                        if bvid and ('bilibili.com' in bvid or 'http' in bvid):
                            bvid = extract_bvid(bvid) or bvid

                        # 1. è·å–è§†é¢‘ä¿¡æ¯
                        v_info_res = run_async(bilibili_service.get_video_info(bvid))
                        if not v_info_res['success']:
                            return {'bvid': bvid, 'success': False, 'error': f"è·å–è§†é¢‘ä¿¡æ¯å¤±è´¥: {v_info_res['error']}"}

                        v_info = v_info_res['data']
                        v_title = v_info.get('title', bvid)

                        # 2. é€ä¸ªè·å–æ‰€æœ‰å¤šç»´å†…å®¹ï¼ˆé¿å…åµŒå¥—äº‹ä»¶å¾ªç¯ï¼‰
                        sub_res = run_async(bilibili_service.get_video_subtitles(bvid))
                        danmaku_res = run_async(bilibili_service.get_video_danmaku(bvid, limit=1000))
                        comments_res = run_async(bilibili_service.get_video_comments(bvid, max_pages=10))
                        frames_res = run_async(bilibili_service.extract_video_frames(bvid))

                        # æ•°æ®è§£æ
                        subtitle_text = sub_res['data']['full_text'] if (not isinstance(sub_res, Exception) and sub_res.get('success') and sub_res['data'].get('has_subtitle')) else ""

                        danmaku_text = ""
                        if not isinstance(danmaku_res, Exception) and danmaku_res.get('success'):
                            danmaku_list = danmaku_res['data']['danmakus']
                            danmaku_text = f"\n\nã€å¼¹å¹•å†…å®¹ï¼ˆéƒ¨åˆ†ï¼‰ã€‘\n" + "\n".join(danmaku_list[:100])

                        comments_text = ""
                        if not isinstance(comments_res, Exception) and comments_res.get('success'):
                            comments_list = [f"{c['username']}: {c['message']}" for c in comments_res['data']['comments'][:50]]
                            comments_text = f"\n\nã€è§†é¢‘è¯„è®ºï¼ˆéƒ¨åˆ†ï¼‰ã€‘\n" + "\n".join(comments_list)

                        video_frames = frames_res['data']['frames'] if (not isinstance(frames_res, Exception) and frames_res.get('success')) else None

                        # æ•´åˆåŸææ–™
                        full_raw_content = subtitle_text if subtitle_text else f"ç®€ä»‹: {v_info.get('desc', 'æ— ')}"
                        full_raw_content += danmaku_text + comments_text

                        # 3. è°ƒç”¨ AI æ·±åº¦åˆ†æ
                        prompt = get_video_analysis_prompt(
                            v_info,
                            full_raw_content,
                            has_video_frames=bool(video_frames),
                            danmaku_content=danmaku_text if danmaku_text else None
                        )

                        # æ„å»ºå¤šæ¨¡æ€å†…å®¹
                        user_content = [{"type": "text", "text": prompt}]
                        if video_frames:
                            for frame_base64 in video_frames:
                                user_content.append({
                                    "type": "image_url",
                                    "image_url": {
                                        "url": f"data:image/jpeg;base64,{frame_base64}",
                                        "detail": "low"
                                    }
                                })

                        # è°ƒç”¨AIåˆ†æ
                        logger.info(f"[æ‰¹é‡åˆ†æ] å¼€å§‹AIåˆ†æ: {bvid} ({v_title})")
                        analysis_response = self.client.chat.completions.create(
                            model=self.vl_model,
                            messages=[
                                {
                                    "role": "system",
                                    "content": "ä½ æ˜¯ä¸€ä½èµ„æ·±çš„Bç«™è§†é¢‘å†…å®¹åˆ†æä¸“å®¶ï¼Œæ“…é•¿ç»“åˆè§†é¢‘ç”»é¢ã€å­—å¹•å’Œèˆ†æƒ…è¿›è¡Œå…¨ç»´åº¦åˆ†æã€‚"
                                },
                                {"role": "user", "content": user_content}
                            ],
                            stream=True
                        )
                        logger.info(f"[æ‰¹é‡åˆ†æ] AIåˆ†æå“åº”å·²æ¥æ”¶: {bvid}")

                        result_text = ""
                        current_analysis_tokens = 0
                        token_count = 0  # åˆå§‹åŒ–

                        for chunk in analysis_response:
                            if not chunk.choices:
                                continue
                            delta = chunk.choices[0].delta
                            if delta.content:
                                result_text += delta.content
                            # æµå¼å“åº”çš„æœ€åä¸€ä¸ªchunkåŒ…å«usageä¿¡æ¯
                            if chunk.usage:
                                token_count = chunk.usage.total_tokens
                                # ä¸è¦ç«‹å³breakï¼Œç»§ç»­å¤„ç†å¯èƒ½çš„å‰©ä½™å†…å®¹

                        # å¦‚æœæ²¡æœ‰è·å–åˆ°usageï¼Œä½¿ç”¨æ–‡æœ¬é•¿åº¦ä¼°ç®—
                        if not token_count:
                            token_count = len(result_text)

                        # è°ƒè¯•æ—¥å¿—ï¼šæ£€æŸ¥result_textå®é™…å†…å®¹
                        logger.info(f"[æ‰¹é‡åˆ†æ] AIåˆ†æå®Œæˆ: {bvid} ({v_title}), tokens: {token_count}, result_texté•¿åº¦: {len(result_text)}")
                        if len(result_text) == 0:
                            logger.error(f"[æ‰¹é‡åˆ†æ] âš ï¸ result_textä¸ºç©º! bvid={bvid}, title={v_title}")
                        elif len(result_text) < 100:
                            logger.warning(f"[æ‰¹é‡åˆ†æ] âš ï¸ result_textå¼‚å¸¸çŸ­: {len(result_text)}å­—ç¬¦, å†…å®¹é¢„è§ˆ: {result_text[:200]}")
                        else:
                            logger.info(f"[æ‰¹é‡åˆ†æ] result_textå†…å®¹é¢„è§ˆï¼ˆå‰200å­—ç¬¦ï¼‰: {result_text[:200]}")

                        return {
                            'bvid': bvid,
                            'success': True,
                            'title': v_info['title'],
                            'summary': result_text,
                            'tokens': token_count
                        }

                    # å¹¶è¡Œæ‰§è¡Œæ‰€æœ‰è§†é¢‘åˆ†æï¼ˆä½¿ç”¨çº¿ç¨‹æ± ï¼‰
                    bvids = [json.loads(tc["function"]["arguments"]).get("bvid") for tc in tool_calls]
                    logger.info(f"[æ‰¹é‡åˆ†æ] å‡†å¤‡å¹¶è¡Œåˆ†æ {len(bvids)} ä¸ªè§†é¢‘: {bvids}")

                    # ä½¿ç”¨ ThreadPoolExecutor å¹¶è¡Œæ‰§è¡ŒåŒæ­¥å‡½æ•°
                    import concurrent.futures
                    with concurrent.futures.ThreadPoolExecutor(max_workers=min(len(bvids), 5)) as executor:
                        future_to_bvid = {executor.submit(analyze_single_video, bvid): bvid for bvid in bvids}
                        results = []
                        for future in concurrent.futures.as_completed(future_to_bvid):
                            try:
                                result = future.result()
                                results.append(result)
                                logger.info(f"[æ‰¹é‡åˆ†æ] å•ä¸ªè§†é¢‘åˆ†æå®Œæˆ: {result.get('bvid', 'unknown')}")
                            except Exception as e:
                                logger.error(f"[æ‰¹é‡åˆ†æ] è§†é¢‘åˆ†æå¼‚å¸¸: {str(e)}")
                                import traceback
                                traceback.print_exc()
                                results.append(e)

                    logger.info(f"[æ‰¹é‡åˆ†æ] æ‰€æœ‰è§†é¢‘åˆ†æå®Œæˆï¼Œå…± {len(results)} ä¸ªç»“æœ")

                    # å¤„ç†å¹¶è¿”å›ç»“æœ
                    total_tokens = 0
                    for i, result in enumerate(results):
                        if isinstance(result, Exception):
                            messages.append({
                                "role": "tool",
                                "tool_call_id": tool_calls[i]["id"],
                                "name": "analyze_video",
                                "content": f"åˆ†æå¤±è´¥: {str(result)}"
                            })
                        elif result.get('success'):
                            total_tokens += result.get('tokens', 0)
                            summary = result.get('summary', '')
                            # ğŸ” è°ƒè¯•æ—¥å¿—ï¼šæ£€æŸ¥ä¼ é€’ç»™AIçš„å·¥å…·å†…å®¹
                            logger.info(f"[æ‰¹é‡åˆ†æ] æ„é€ å·¥å…·æ¶ˆæ¯: bvid={result['bvid']}, summaryé•¿åº¦={len(summary)}")
                            if len(summary) == 0:
                                logger.error(f"[æ‰¹é‡åˆ†æ] âŒ summaryä¸ºç©º! bvid={result['bvid']}, result keys={list(result.keys())}")
                            elif len(summary) < 100:
                                logger.warning(f"[æ‰¹é‡åˆ†æ] âš ï¸ summaryå¼‚å¸¸çŸ­: {len(summary)}å­—ç¬¦, å†…å®¹: {summary[:200]}")
                            else:
                                logger.info(f"[æ‰¹é‡åˆ†æ] âœ… summaryæ­£å¸¸: {len(summary)}å­—ç¬¦, å‰100å­—ç¬¦: {summary[:100]}")

                            messages.append({
                                "role": "tool",
                                "tool_call_id": tool_calls[i]["id"],
                                "name": "analyze_video",
                                "content": f"è§†é¢‘åˆ†æå®Œæˆ: {result.get('title', result['bvid'])}\n\nåˆ†æç»“æœ:\n{summary}"
                            })
                            # å‘é€è¿›åº¦æ›´æ–°
                            yield {
                                'type': 'tool_progress',
                                'tool': 'analyze_video',
                                'bvid': result['bvid'],
                                'message': f"âœ… {result.get('title', result['bvid'])} åˆ†æå®Œæˆ",
                                'tokens': total_tokens,
                                'video_tokens': result.get('tokens', 0),
                                'title': result.get('title', '')
                            }
                        else:
                            messages.append({
                                "role": "tool",
                                "tool_call_id": tool_calls[i]["id"],
                                "name": "analyze_video",
                                "content": f"åˆ†æå¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}"
                            })

                    # å‘é€å®Œæˆé€šçŸ¥
                    success_count = sum(1 for r in results if not isinstance(r, Exception) and r.get('success'))
                    logger.info(f"[æ‰¹é‡åˆ†æ] å‘é€å®Œæˆé€šçŸ¥: total={len(tool_calls)}, success={success_count}, tokens={total_tokens}")

                    yield {
                        'type': 'batch_analyze_complete',
                        'total': len(tool_calls),
                        'success': success_count,
                        'tokens': total_tokens
                    }
                    continue  # è·³è¿‡æ™®é€šçš„å·¥å…·è°ƒç”¨å¤„ç†

                # æ­£å¸¸çš„å·¥å…·è°ƒç”¨å¤„ç†
                is_final_report_triggered = False
                for tool_call in tool_calls:
                    func_name = tool_call["function"]["name"]
                    try:
                        args = json.loads(tool_call["function"]["arguments"])
                    except:
                        args = {}

                    yield {'type': 'tool_start', 'tool': func_name, 'args': args}

                    result = ""
                    try:
                        result = yield from self._execute_tool(
                            func_name, args, bilibili_service, topic
                        )
                    except Exception as e:
                        error_msg = str(e)
                        # å‹å¥½çš„401é”™è¯¯æç¤º
                        if "401" in error_msg or "Invalid token" in error_msg:
                            error_msg = "API Key æ ¡éªŒå¤±è´¥ï¼ˆ401 - Invalid tokenï¼‰ã€‚è¯·åœ¨è®¾ç½®ä¸­æ£€æŸ¥æ‚¨çš„ OpenAI API Key å’Œ API Base æ˜¯å¦æ­£ç¡®ã€‚"
                        result = f"æ‰§è¡Œå·¥å…·å‡ºé”™: {error_msg}"
                        yield {'type': 'error', 'error': error_msg}

                    messages.append({
                        "role": "tool",
                        "tool_call_id": tool_call["id"],
                        "name": func_name,
                        "content": result
                    })

                    # æ£€æŸ¥æ˜¯å¦è§¦å‘äº†æœ€ç»ˆæŠ¥å‘Š
                    if func_name == "finish_research_and_write_report":
                        is_final_report_triggered = True

                # å¦‚æœè§¦å‘äº†æœ€ç»ˆæŠ¥å‘Šæ’°å†™ï¼Œè¿›å…¥æœ€åä¸€æ®µç”Ÿæˆ
                if is_final_report_triggered:
                    yield {'type': 'report_start'}

                    # æ„å»ºAPIè¯·æ±‚å‚æ•°
                    final_request_params = {
                        "model": self.model,
                        "messages": messages,
                        "stream": True
                    }

                    # å¦‚æœå¯ç”¨æ€è€ƒæ¨¡å¼ï¼Œæ·»åŠ é¢å¤–å‚æ•°
                    if self.enable_thinking:
                        pass  # æ¨¡å‹ä¼šè‡ªåŠ¨è¿”å› reasoning_content

                    final_stream = self.client.chat.completions.create(**final_request_params)
                    final_report = ""
                    for chunk in final_stream:
                        if not chunk.choices:
                            continue
                        delta = chunk.choices[0].delta
                        if hasattr(delta, 'reasoning_content') and delta.reasoning_content:
                            yield {'type': 'thinking', 'content': delta.reasoning_content}
                        if delta.content:
                            final_report += delta.content
                            yield {'type': 'content', 'content': delta.content}

                    # æŒä¹…åŒ–æŠ¥å‘Š
                    try:
                        save_research_report(topic, final_report)
                    except Exception as e:
                        logger.warning(f"ä¿å­˜æŠ¥å‘Šå¤±è´¥: {e}")

                    break

            yield {'type': 'done'}

        except Exception as e:
            error_msg = str(e)
            # å‹å¥½çš„401é”™è¯¯æç¤º
            if "401" in error_msg or "Invalid token" in error_msg:
                error_msg = "API Key æ ¡éªŒå¤±è´¥ï¼ˆ401 - Invalid tokenï¼‰ã€‚è¯·åœ¨è®¾ç½®ä¸­æ£€æŸ¥æ‚¨çš„ OpenAI API Key å’Œ API Base æ˜¯å¦æ­£ç¡®ã€‚"
            logger.error(f"æ·±åº¦ç ”ç©¶å¤±è´¥: {error_msg}")
            import traceback
            traceback.print_exc()
            yield {'type': 'error', 'error': error_msg}

    def _get_tools_definition(self) -> list:
        """è·å–å·¥å…·å®šä¹‰"""
        return [
            {
                "type": "function",
                "function": {
                    "name": "search_videos",
                    "description": "æœç´¢ B ç«™è§†é¢‘ä»¥è·å–ç›¸å…³ç ”ç©¶ç´ æ",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "keyword": {"type": "string", "description": "æœç´¢å…³é”®è¯"}
                        },
                        "required": ["keyword"]
                    }
                }
            },
            {
                "type": "function",
                "function": {
                    "name": "search_users",
                    "description": "æ ¹æ®å…³é”®è¯/æ˜µç§°æ¨¡ç³Šæœç´¢ B ç«™ UP ä¸»",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "keyword": {"type": "string", "description": "UP ä¸»æ˜µç§°æˆ–ç›¸å…³å…³é”®è¯"}
                        },
                        "required": ["keyword"]
                    }
                }
            },
            {
                "type": "function",
                "function": {
                    "name": "get_user_recent_videos",
                    "description": "è·å–æŒ‡å®š UP ä¸»çš„æœ€è¿‘æŠ•ç¨¿è§†é¢‘åˆ—è¡¨ï¼Œç”¨äºç³»ç»Ÿæ€§ç ”ç©¶è¯¥ UP ä¸»çš„ä¸“ä¸šå†…å®¹",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "mid": {"type": "integer", "description": "UP ä¸»çš„ UID (mid)", "default": 10},
                            "limit": {"type": "integer", "description": "è·å–è§†é¢‘çš„æ•°é‡ï¼Œé»˜è®¤ 10"}
                        },
                        "required": ["mid"]
                    }
                }
            },
            {
                "type": "function",
                "function": {
                    "name": "analyze_video",
                    "description": "å¯¹æŒ‡å®šçš„ B ç«™è§†é¢‘è¿›è¡Œæ·±åº¦ AI å†…å®¹åˆ†æ",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "bvid": {"type": "string", "description": "è§†é¢‘çš„ BV å·"}
                        },
                        "required": ["bvid"]
                    }
                }
            },
            {
                "type": "function",
                "function": {
                    "name": "web_search",
                    "description": "ä½¿ç”¨ Exa AI è¿›è¡Œå…¨ç½‘æ·±åº¦æœç´¢ï¼Œè·å–æœ€æ–°èµ„è®¯ã€æŠ€æœ¯æ–‡æ¡£æˆ– B ç«™ä»¥å¤–çš„è¡¥å……ä¿¡æ¯",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "query": {"type": "string", "description": "æœç´¢æŸ¥è¯¢è¯­å¥"}
                        },
                        "required": ["query"]
                    }
                }
            },
            {
                "type": "function",
                "function": {
                    "name": "get_hot_videos",
                    "description": "è·å–Bç«™å½“å‰çƒ­é—¨è§†é¢‘ï¼Œäº†è§£æµè¡Œè¶‹åŠ¿å’Œçƒ­ç‚¹è¯é¢˜ã€‚é€‚åˆç ”ç©¶å½“å‰çƒ­é—¨å†…å®¹ã€æµè¡Œè¶‹åŠ¿ç­‰è¯¾é¢˜ã€‚",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "page": {"type": "integer", "description": "é¡µç ï¼Œé»˜è®¤1"},
                            "limit": {"type": "integer", "description": "æ¯é¡µæ•°é‡ï¼Œé»˜è®¤20"}
                        },
                        "required": []
                    }
                }
            },
            {
                "type": "function",
                "function": {
                    "name": "get_hot_buzzwords",
                    "description": "è·å–Bç«™çƒ­è¯å›¾é‰´ï¼Œäº†è§£ç½‘ç»œæµè¡Œè¯­ã€æ¢—æ–‡åŒ–å’Œç¤¾åŒºçƒ­ç‚¹è¯é¢˜ã€‚é€‚åˆç ”ç©¶ç½‘ç»œæ–‡åŒ–ã€è¯­è¨€ç‰¹ç‚¹ã€æ¢—æ–‡åŒ–ç­‰è¯¾é¢˜ã€‚",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "page": {"type": "integer", "description": "é¡µç ï¼Œé»˜è®¤1"}
                        },
                        "required": []
                    }
                }
            },
            {
                "type": "function",
                "function": {
                    "name": "get_weekly_hot_videos",
                    "description": "è·å–Bç«™æ¯å‘¨ç²¾é€‰ä¼˜è´¨è§†é¢‘ï¼ˆæ¯å‘¨å¿…çœ‹ï¼‰ã€‚é€‚åˆç ”ç©¶é«˜è´¨é‡å†…å®¹æ ‡å‡†ã€å£ç¢‘è§†é¢‘ç‰¹ç‚¹ã€å„åˆ†åŒºä»£è¡¨ä½œç­‰è¯¾é¢˜ã€‚",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "week": {"type": "integer", "description": "ç¬¬å‡ å‘¨ï¼Œé»˜è®¤1"}
                        },
                        "required": []
                    }
                }
            },
            {
                "type": "function",
                "function": {
                    "name": "get_history_popular_videos",
                    "description": "è·å–Bç«™å…¥ç«™å¿…åˆ·çš„85ä¸ªç»å…¸è§†é¢‘ã€‚é€‚åˆç ”ç©¶Bç«™æ–‡åŒ–å†å²ã€ç»å…¸ä½œå“ç‰¹ç‚¹ã€ç¤¾åŒºæ–‡åŒ–åŸºå› ç­‰è¯¾é¢˜ã€‚",
                    "parameters": {
                        "type": "object",
                        "properties": {},
                        "required": []
                    }
                }
            },
            {
                "type": "function",
                "function": {
                    "name": "get_rank_videos",
                    "description": "è·å–æŒ‡å®šåˆ†åŒºçš„è§†é¢‘æ’è¡Œæ¦œã€‚æ”¯æŒ30+åˆ†åŒºï¼ˆçŸ¥è¯†ã€ç§‘æŠ€ã€æ¸¸æˆã€éŸ³ä¹ç­‰ï¼‰ã€‚é€‚åˆå‚ç›´é¢†åŸŸç ”ç©¶ã€åˆ†åŒºå†…å®¹ç‰¹ç‚¹åˆ†æç­‰è¯¾é¢˜ã€‚",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "category": {"type": "string", "description": "åˆ†åŒºç±»å‹ï¼Œå¦‚ knowledgeï¼ˆçŸ¥è¯†ï¼‰ã€technologyï¼ˆç§‘æŠ€ï¼‰ã€gameï¼ˆæ¸¸æˆï¼‰ã€musicï¼ˆéŸ³ä¹ï¼‰ç­‰"},
                            "day": {"type": "integer", "description": "æ—¶é—´èŒƒå›´ï¼š3=ä¸‰æ—¥æ’è¡Œï¼Œ7=å‘¨æ’è¡Œ"}
                        },
                        "required": ["category"]
                    }
                }
            },
            {
                "type": "function",
                "function": {
                    "name": "finish_research_and_write_report",
                    "description": "å®Œæˆæ‰€æœ‰èµ„æ–™æœé›†ï¼Œå¼€å§‹æ’°å†™æœ€ç»ˆè¯¦å°½çš„ç ”ç©¶æŠ¥å‘Š",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "summary_of_findings": {"type": "string", "description": "å¯¹ç ”ç©¶å‘ç°çš„ç®€è¦æ¦‚è¿°"}
                        },
                        "required": ["summary_of_findings"]
                    }
                }
            },
            {
                "type": "function",
                "function": {
                    "name": "get_search_suggestions",
                    "description": "è·å–æœç´¢è”æƒ³å»ºè®®ï¼Œä¼˜åŒ–æœç´¢è¯ä»¥è·å¾—æ›´ç²¾å‡†çš„æœç´¢ç»“æœ",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "keyword": {"type": "string", "description": "éƒ¨åˆ†æœç´¢å…³é”®è¯"}
                        },
                        "required": ["keyword"]
                    }
                }
            },
            {
                "type": "function",
                "function": {
                    "name": "get_hot_search_keywords",
                    "description": "è·å–å½“å‰ B ç«™çƒ­æœå…³é”®è¯ï¼ŒæŠŠæ¡çƒ­ç‚¹è¶‹åŠ¿å’Œç”¨æˆ·å…³æ³¨ç„¦ç‚¹",
                    "parameters": {
                        "type": "object",
                        "properties": {},
                        "required": []
                    }
                }
            },
            {
                "type": "function",
                "function": {
                    "name": "get_video_tags",
                    "description": "è·å–è§†é¢‘çš„æ ‡ç­¾ä¿¡æ¯ï¼Œäº†è§£è§†é¢‘çš„åˆ†ç±»ã€ä¸»é¢˜å’Œå…³è”å†…å®¹",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "bvid": {"type": "string", "description": "è§†é¢‘çš„ BV å·"}
                        },
                        "required": ["bvid"]
                    }
                }
            },
            {
                "type": "function",
                "function": {
                    "name": "get_video_series",
                    "description": "è·å–è§†é¢‘æ‰€å±çš„åˆé›†ä¿¡æ¯ï¼Œç”¨äºç³»ç»Ÿæ€§å­¦ä¹ ç³»åˆ—æ•™ç¨‹æˆ–äº†è§£å®Œæ•´çš„çŸ¥è¯†ä½“ç³»",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "bvid": {"type": "string", "description": "è§†é¢‘çš„ BV å·"}
                        },
                        "required": ["bvid"]
                    }
                }
            },
            {
                "type": "function",
                "function": {
                    "name": "get_user_dynamics",
                    "description": "è·å– UP ä¸»çš„æœ€æ–°åŠ¨æ€ï¼Œäº†è§£å…¶æ—¥å¸¸è¿è¥ã€ç¤¾äº¤äº’åŠ¨å’Œæœ€æ–°æƒ³æ³•",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "mid": {"type": "integer", "description": "UP ä¸»çš„ UID (mid)", "default": 10},
                            "limit": {"type": "integer", "description": "è·å–åŠ¨æ€çš„æ•°é‡ï¼Œé»˜è®¤ 10"}
                        },
                        "required": ["mid"]
                    }
                }
            }
        ]

    def _execute_tool(self, func_name: str, args: Dict, bilibili_service, topic: str):
        """
        æ‰§è¡Œå·¥å…·è°ƒç”¨

        Args:
            func_name: å·¥å…·åç§°
            args: å·¥å…·å‚æ•°
            bilibili_service: Bç«™æœåŠ¡å®ä¾‹
            topic: ç ”ç©¶è¯¾é¢˜

        Yields:
            Dict: å·¥å…·æ‰§è¡Œç»“æœ
        """
        from src.backend.services.bilibili.bilibili_service import run_async
        from src.backend.utils.bilibili_helpers import extract_bvid
        from src.backend.services.ai.prompts import get_video_analysis_prompt

        if func_name == "search_videos":
            keyword = args.get("keyword")
            search_res = run_async(bilibili_service.search_videos(keyword, limit=5))
            if search_res['success']:
                result = json.dumps(search_res['data'], ensure_ascii=False)
                yield {'type': 'tool_result', 'tool': func_name, 'result': search_res['data'][:3]}
            else:
                result = f"æœç´¢å¤±è´¥: {search_res['error']}"

        elif func_name == "web_search":
            query = args.get("query")
            search_res = web_search_exa(query)
            if search_res['success']:
                result = json.dumps(search_res['data'], ensure_ascii=False)
                yield {'type': 'tool_result', 'tool': func_name, 'result': search_res['data']}
            else:
                result = f"ç½‘ç»œæœç´¢å¤±è´¥: {search_res['error']}"
                yield {'type': 'error', 'error': result}

        elif func_name == "analyze_video":
            bvid = args.get("bvid")
            # æ¸…ç†BVID
            if bvid and ('bilibili.com' in bvid or 'http' in bvid):
                bvid = extract_bvid(bvid) or bvid

            logger.info(f"[å·¥å…·] æ·±åº¦ç ”ç©¶ Agent å‘èµ·è§†é¢‘åˆ†æ: {bvid}")

            # 1. è·å–è§†é¢‘ä¿¡æ¯
            v_info_res = run_async(bilibili_service.get_video_info(bvid))
            if not v_info_res['success']:
                result = f"è·å–è§†é¢‘ä¿¡æ¯å¤±è´¥: {v_info_res['error']}"
            else:
                v_info = v_info_res['data']
                v_title = v_info.get('title', bvid)

                # 2. é€ä¸ªè·å–æ‰€æœ‰å¤šç»´å†…å®¹ï¼ˆé¿å…åµŒå¥—äº‹ä»¶å¾ªç¯ï¼‰
                yield {'type': 'tool_progress', 'tool': func_name, 'bvid': bvid, 'title': v_title, 'message': f'å·²è·å–è§†é¢‘æ ‡é¢˜: {v_title}ã€‚æ­£åœ¨æœé›†å…¨ç»´ä¿¡æ¯...'}

                sub_res = run_async(bilibili_service.get_video_subtitles(bvid))
                danmaku_res = run_async(bilibili_service.get_video_danmaku(bvid, limit=1000))
                comments_res = run_async(bilibili_service.get_video_comments(bvid, max_pages=10))
                frames_res = run_async(bilibili_service.extract_video_frames(bvid))

                # æ•°æ®è§£æ
                subtitle_text = sub_res['data']['full_text'] if (not isinstance(sub_res, Exception) and sub_res.get('success') and sub_res['data'].get('has_subtitle')) else ""

                danmaku_text = ""
                if not isinstance(danmaku_res, Exception) and danmaku_res.get('success'):
                    danmaku_list = danmaku_res['data']['danmakus']
                    danmaku_text = f"\n\nã€å¼¹å¹•å†…å®¹ï¼ˆéƒ¨åˆ†ï¼‰ã€‘\n" + "\n".join(danmaku_list[:100])

                comments_text = ""
                if not isinstance(comments_res, Exception) and comments_res.get('success'):
                    comments_list = [f"{c['username']}: {c['message']}" for c in comments_res['data']['comments'][:50]]
                    comments_text = f"\n\nã€è§†é¢‘è¯„è®ºï¼ˆéƒ¨åˆ†ï¼‰ã€‘\n" + "\n".join(comments_list)

                video_frames = frames_res['data']['frames'] if (not isinstance(frames_res, Exception) and frames_res.get('success')) else None

                # æ•´åˆåŸææ–™
                full_raw_content = subtitle_text if subtitle_text else f"ç®€ä»‹: {v_info.get('desc', 'æ— ')}"
                full_raw_content += danmaku_text + comments_text

                # 3. è°ƒç”¨ AI æ·±åº¦åˆ†æï¼ˆæµå¼åé¦ˆè¿›åº¦ï¼‰
                yield {'type': 'tool_progress', 'tool': func_name, 'bvid': bvid, 'message': 'å…¨ç»´ç´ æå°±ç»ªï¼Œæ­£åœ¨è¿›è¡Œè§†è§‰ä¸æ–‡æœ¬äº¤å‰å»ºæ¨¡...'}

                prompt = get_video_analysis_prompt(
                    v_info,
                    full_raw_content,
                    has_video_frames=bool(video_frames),
                    danmaku_content=danmaku_text if danmaku_text else None
                )

                # æ„å»ºå¤šæ¨¡æ€å†…å®¹
                user_content = [{"type": "text", "text": prompt}]
                if video_frames:
                    for frame_base64 in video_frames:
                        user_content.append({
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/jpeg;base64,{frame_base64}",
                                "detail": "low"
                            }
                        })

                analysis_stream = self.client.chat.completions.create(
                    model=self.vl_model,
                    messages=[
                        {
                            "role": "system",
                            "content": "ä½ æ˜¯ä¸€ä½èµ„æ·±çš„Bç«™è§†é¢‘å†…å®¹åˆ†æä¸“å®¶ï¼Œæ“…é•¿ç»“åˆè§†é¢‘ç”»é¢ã€å­—å¹•å’Œèˆ†æƒ…è¿›è¡Œå…¨ç»´åº¦åˆ†æã€‚"
                        },
                        {"role": "user", "content": user_content}
                    ],
                    stream=True
                )

                result_text = ""
                current_analysis_tokens = 0
                for analysis_chunk in analysis_stream:
                    if not analysis_chunk.choices:
                        continue
                    delta = analysis_chunk.choices[0].delta
                    if delta.content:
                        result_text += delta.content
                        current_analysis_tokens = len(result_text)
                        yield {
                            'type': 'tool_progress',
                            'tool': func_name,
                            'bvid': bvid,
                            'tokens': current_analysis_tokens,
                            'content': delta.content
                        }

                result = result_text
                yield {
                    'type': 'tool_result',
                    'tool': func_name,
                    'result': {'bvid': bvid, 'title': v_info['title'], 'summary': result},
                    'tokens': current_analysis_tokens
                }

        elif func_name == "search_users":
            keyword = args.get("keyword")
            search_res = run_async(bilibili_service.search_users(keyword, limit=5))
            if search_res['success']:
                result = json.dumps(search_res['data'], ensure_ascii=False)
                yield {'type': 'tool_result', 'tool': func_name, 'result': search_res['data']}
            else:
                result = f"æœç´¢ç”¨æˆ·å¤±è´¥: {search_res['error']}"

        elif func_name == "get_user_recent_videos":
            mid = args.get("mid")
            limit = args.get("limit", 10)
            v_res = run_async(bilibili_service.get_user_recent_videos(mid, limit=limit))
            if v_res['success']:
                result = json.dumps(v_res['data'], ensure_ascii=False)
                yield {'type': 'tool_result', 'tool': func_name, 'result': v_res['data']}
            else:
                result = f"è·å–ç”¨æˆ·ä½œå“å¤±è´¥: {v_res['error']}"

        elif func_name == "get_hot_videos":
            page = args.get("page", 1)
            limit = args.get("limit", 20)
            hot_res = run_async(bilibili_service.get_hot_videos(pn=page, ps=limit))
            if hot_res['success']:
                result = json.dumps(hot_res['data'], ensure_ascii=False)
                yield {'type': 'tool_result', 'tool': func_name, 'result': hot_res['data']}
            else:
                result = f"è·å–çƒ­é—¨è§†é¢‘å¤±è´¥: {hot_res['error']}"
                yield {'type': 'error', 'error': result}

        elif func_name == "get_hot_buzzwords":
            page = args.get("page", 1)
            buzz_res = run_async(bilibili_service.get_hot_buzzwords(page_num=page, page_size=20))
            if buzz_res['success']:
                result = json.dumps(buzz_res['data'], ensure_ascii=False)
                yield {'type': 'tool_result', 'tool': func_name, 'result': buzz_res['data']}
            else:
                result = f"è·å–çƒ­è¯å›¾é‰´å¤±è´¥: {buzz_res['error']}"
                yield {'type': 'error', 'error': result}

        elif func_name == "get_weekly_hot_videos":
            week = args.get("week", 1)
            weekly_res = run_async(bilibili_service.get_weekly_hot_videos(week=week))
            if weekly_res['success']:
                result = json.dumps(weekly_res['data'], ensure_ascii=False)
                yield {'type': 'tool_result', 'tool': func_name, 'result': weekly_res['data']}
            else:
                result = f"è·å–æ¯å‘¨å¿…çœ‹å¤±è´¥: {weekly_res['error']}"
                yield {'type': 'error', 'error': result}

        elif func_name == "get_history_popular_videos":
            history_res = run_async(bilibili_service.get_history_popular_videos())
            if history_res['success']:
                result = json.dumps(history_res['data'], ensure_ascii=False)
                yield {'type': 'tool_result', 'tool': func_name, 'result': history_res['data']}
            else:
                result = f"è·å–å…¥ç«™å¿…åˆ·å¤±è´¥: {history_res['error']}"
                yield {'type': 'error', 'error': result}

        elif func_name == "get_rank_videos":
            category = args.get("category")
            day = args.get("day", 3)

            # æ˜ å°„åˆ†åŒºåç§°åˆ° bilibili_api çš„ RankType
            from bilibili_api import rank
            category_map = {
                'knowledge': rank.RankType.Knowledge,
                'technology': rank.RankType.Technology,
                'game': rank.RankType.Game,
                'music': rank.RankType.Music,
                'douga': rank.RankType.Douga,
                'dance': rank.RankType.Dance,
                'life': rank.RankType.Life,
                'food': rank.RankType.Food,
                'fashion': rank.RankType.Fashion,
                'ent': rank.RankType.Ent,
                'cinephile': rank.RankType.Cinephile,
                'sports': rank.RankType.Sports,
                'car': rank.RankType.Car,
                'animal': rank.RankType.Animal,
            }

            rank_type = category_map.get(category.lower())
            if not rank_type:
                result = f"ä¸æ”¯æŒçš„åˆ†åŒºç±»å‹: {category}ã€‚æ”¯æŒçš„åˆ†åŒºåŒ…æ‹¬: knowledge, technology, game, music, douga, dance, life, food, fashion, ent, cinephile, sports, car, animal"
                yield {'type': 'error', 'error': result}
            else:
                rank_res = run_async(bilibili_service.get_rank_videos(type_=rank_type))
                if rank_res['success']:
                    result = json.dumps(rank_res['data'], ensure_ascii=False)
                    yield {'type': 'tool_result', 'tool': func_name, 'result': rank_res['data']}
                else:
                    result = f"è·å–æ’è¡Œæ¦œå¤±è´¥: {rank_res['error']}"
                    yield {'type': 'error', 'error': result}

        elif func_name == "finish_research_and_write_report":
            result = "èµ„æ–™æœé›†é˜¶æ®µç»“æŸã€‚è¯·ç°åœ¨æ’°å†™å…¨æ–¹ä½ã€æ·±åº¦çš„ç ”ç©¶æŠ¥å‘Šï¼Œå¹¶ä¸¥æ ¼éµå®ˆå‚è€ƒæ¥æºæ ‡æ³¨è§„èŒƒã€‚"
            yield {'type': 'tool_result', 'tool': func_name, 'result': 'è¿›å…¥æ’°å†™æŠ¥å‘Šé˜¶æ®µ...'}

        elif func_name == "get_search_suggestions":
            keyword = args.get("keyword")
            sug_res = run_async(bilibili_service.get_search_suggestions(keyword))
            if sug_res['success']:
                result = json.dumps(sug_res['data'], ensure_ascii=False)
                yield {'type': 'tool_result', 'tool': func_name, 'result': sug_res['data']}
            else:
                result = f"è·å–æœç´¢å»ºè®®å¤±è´¥: {sug_res['error']}"

        elif func_name == "get_hot_search_keywords":
            hot_res = run_async(bilibili_service.get_hot_search_keywords())
            if hot_res['success']:
                result = json.dumps(hot_res['data'], ensure_ascii=False)
                yield {'type': 'tool_result', 'tool': func_name, 'result': hot_res['data']}
            else:
                result = f"è·å–çƒ­æœå…³é”®è¯å¤±è´¥: {hot_res['error']}"

        elif func_name == "get_video_tags":
            bvid = args.get("bvid")
            tags_res = run_async(bilibili_service.get_video_tags(bvid))
            if tags_res['success']:
                result = json.dumps(tags_res['data'], ensure_ascii=False)
                yield {'type': 'tool_result', 'tool': func_name, 'result': tags_res['data']}
            else:
                result = f"è·å–è§†é¢‘æ ‡ç­¾å¤±è´¥: {tags_res['error']}"

        elif func_name == "get_video_series":
            bvid = args.get("bvid")
            series_res = run_async(bilibili_service.get_video_series(bvid))
            if series_res['success']:
                result = json.dumps(series_res['data'], ensure_ascii=False)
                yield {'type': 'tool_result', 'tool': func_name, 'result': series_res['data']}
            else:
                result = f"è·å–è§†é¢‘åˆé›†å¤±è´¥: {series_res['error']}"

        elif func_name == "get_user_dynamics":
            mid = args.get("mid")
            limit = args.get("limit", 10)
            dynamics_res = run_async(bilibili_service.get_user_dynamics(mid, limit=limit))
            if dynamics_res['success']:
                result = json.dumps(dynamics_res['data'], ensure_ascii=False)
                yield {'type': 'tool_result', 'tool': func_name, 'result': dynamics_res['data']}
            else:
                result = f"è·å–ç”¨æˆ·åŠ¨æ€å¤±è´¥: {dynamics_res['error']}"

        return result
